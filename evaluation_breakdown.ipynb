{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5dc8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from typing import Optional, Union, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils._pytree import tree_flatten, tree_unflatten, tree_map\n",
    "\n",
    "from rich import progress\n",
    "\n",
    "from spanet import JetReconstructionModel, Options\n",
    "from spanet.dataset.types import Evaluation, Outputs, Source\n",
    "from spanet.network.jet_reconstruction.jet_reconstruction_network import extract_predictions\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c28ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_concatenate(tree):\n",
    "    output = {}\n",
    "    for key, value in tree.items():\n",
    "        if isinstance(value, dict):\n",
    "            output[key] = dict_concatenate(value)\n",
    "        else:\n",
    "            output[key] = np.concatenate(value)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def tree_concatenate(trees):\n",
    "    leaves = []\n",
    "    for tree in trees:\n",
    "        data, tree_spec = tree_flatten(tree)\n",
    "        leaves.append(data)\n",
    "\n",
    "    results = [np.concatenate(l) for l in zip(*leaves)]\n",
    "    return tree_unflatten(results, tree_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "624df98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(\n",
    "    log_directory: str,\n",
    "    testing_file: Optional[str] = None,\n",
    "    event_info_file: Optional[str] = None,\n",
    "    batch_size: Optional[int] = None,\n",
    "    cuda: bool = False,\n",
    "    fp16: bool = False,\n",
    "    checkpoint: Optional[str] = None\n",
    ") -> JetReconstructionModel:\n",
    "    # Load the best-performing checkpoint on validation data\n",
    "    if checkpoint is None:\n",
    "        checkpoint = f\"{log_directory}/checkpoints/best-checkpoint.ckpt\" #choosing the best checkpoint (rather than the last checkpoint)\n",
    "#         checkpoint = sorted(glob(f\"{log_directory}/checkpoints/epoch*\"))[-1]\n",
    "\n",
    "        print(f\"Loading: {checkpoint}\")\n",
    "\n",
    "    checkpoint = torch.load(checkpoint, map_location='cpu')\n",
    "    checkpoint = checkpoint[\"state_dict\"]\n",
    "    if fp16:\n",
    "        checkpoint = tree_map(lambda x: x.half(), checkpoint)\n",
    "\n",
    "    # Load the options that were used for this run and set the testing-dataset value\n",
    "    \n",
    "    options = Options.load(f\"{log_directory}/options.json\")\n",
    "#     options = Options.load(\"options_SPANet_modified_08_02.json\")\n",
    "    print('Event_info_file: ', options.event_info_file)\n",
    "    print('testing_file: ', options.testing_file)\n",
    "    print('training_file: ', options.training_file)\n",
    "\n",
    "    # Override options from command line arguments\n",
    "    if testing_file is not None:\n",
    "        options.testing_file = testing_file\n",
    "#         print('new_testing_file')\n",
    "\n",
    "    if event_info_file is not None:\n",
    "        options.event_info_file = event_info_file\n",
    "#         print('new_event_info_file')\n",
    "\n",
    "    if batch_size is not None:\n",
    "        options.batch_size = batch_size\n",
    "#         print('new_batch_size')\n",
    "\n",
    "    # Create model and disable all training operations for speed\n",
    "    model = JetReconstructionModel(options)\n",
    "    print('model_constructed')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model = model.eval()\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad_(False)\n",
    "\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1862615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./lightning_logs/SPANet_modified_08_02/checkpoints/best-checkpoint.ckpt\n",
      "Event_info_file:  semi_leptonic_ttbar.yaml\n",
      "testing_file:  events_h5_files/testing_SPANet_02.h5\n",
      "training_file:  events_h5_files/training_SPANet_08.h5\n",
      "Index Range: 0...1653124\n",
      "Index Range: 1653125...1740131\n",
      "Index Range: 0...440690\n",
      "model_constructed\n"
     ]
    }
   ],
   "source": [
    "log_directory = \"./lightning_logs/SPANet_modified_08_02\"\n",
    "model = load_model(log_directory, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21383269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc856ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7db5be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_dataset(\n",
    "        model: JetReconstructionModel,\n",
    "        progress=progress,\n",
    "        return_full_output: bool = False,\n",
    "        fp16: bool = False\n",
    ") -> Union[Evaluation, Tuple[Evaluation, Outputs]]:\n",
    "    full_assignments = defaultdict(list)\n",
    "    full_assignment_probabilities = defaultdict(list)\n",
    "    full_detection_probabilities = defaultdict(list)\n",
    "\n",
    "    full_classifications = defaultdict(list)\n",
    "    full_regressions = defaultdict(list)\n",
    "\n",
    "    full_outputs = []\n",
    "\n",
    "    dataloader = model.test_dataloader()\n",
    "    if progress:\n",
    "        dataloader = progress.track(model.test_dataloader(), description=\"Evaluating Model\")\n",
    "\n",
    "    for batch in dataloader:\n",
    "        sources = tuple(Source(x[0].to(model.device), x[1].to(model.device)) for x in batch.sources)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=fp16):\n",
    "            outputs = model.forward(sources)\n",
    "\n",
    "        assignment_indices = extract_predictions([\n",
    "            np.nan_to_num(assignment.detach().cpu().numpy(), -np.inf)\n",
    "            for assignment in outputs.assignments\n",
    "        ])\n",
    "\n",
    "        detection_probabilities = np.stack([\n",
    "            torch.sigmoid(detection).cpu().numpy()\n",
    "            for detection in outputs.detections\n",
    "        ])\n",
    "\n",
    "        classifications = {\n",
    "            key: torch.softmax(classification, 1).cpu().numpy()\n",
    "            for key, classification in outputs.classifications.items()\n",
    "        }\n",
    "\n",
    "        regressions = {\n",
    "            key: value.cpu().numpy()\n",
    "            for key, value in outputs.regressions.items()\n",
    "        }\n",
    "\n",
    "        assignment_probabilities = []\n",
    "        dummy_index = torch.arange(assignment_indices[0].shape[0])\n",
    "        for assignment_probability, assignment, symmetries in zip(\n",
    "            outputs.assignments,\n",
    "            assignment_indices,\n",
    "            model.event_info.product_symbolic_groups.values()\n",
    "        ):\n",
    "            # Get the probability of the best assignment.\n",
    "            # Have to use explicit function call here to construct index dynamically.\n",
    "            assignment_probability = assignment_probability.__getitem__((dummy_index, *assignment.T))\n",
    "\n",
    "            # Convert from log-probability to probability.\n",
    "            assignment_probability = torch.exp(assignment_probability)\n",
    "\n",
    "            # Multiply by the symmetry factor to account for equivalent predictions.\n",
    "            assignment_probability = symmetries.order() * assignment_probability\n",
    "\n",
    "            # Convert back to cpu and add to database.\n",
    "            assignment_probabilities.append(assignment_probability.cpu().numpy())\n",
    "\n",
    "        for i, name in enumerate(model.event_info.product_particles):\n",
    "            full_assignments[name].append(assignment_indices[i])\n",
    "            full_assignment_probabilities[name].append(assignment_probabilities[i])\n",
    "            full_detection_probabilities[name].append(detection_probabilities[i])\n",
    "\n",
    "        for key, regression in regressions.items():\n",
    "            full_regressions[key].append(regression)\n",
    "\n",
    "        for key, classification in classifications.items():\n",
    "            full_classifications[key].append(classification)\n",
    "\n",
    "        if return_full_output:\n",
    "            full_outputs.append(tree_map(lambda x: x.cpu().numpy(), outputs))\n",
    "\n",
    "    evaluation = Evaluation(\n",
    "        dict_concatenate(full_assignments),\n",
    "        dict_concatenate(full_assignment_probabilities),\n",
    "        dict_concatenate(full_detection_probabilities),\n",
    "        dict_concatenate(full_regressions),\n",
    "        dict_concatenate(full_classifications)\n",
    "    )\n",
    "\n",
    "    if return_full_output:\n",
    "        return evaluation, tree_concatenate(full_outputs)\n",
    "\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ea829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
