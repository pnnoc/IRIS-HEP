{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1884e161-5d34-4043-a6d7-956ec632cbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "# from coffea.analysis_tools import PackedSelection\n",
    "import torch\n",
    "# from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "import utils\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcba49de-c5fc-4232-be2d-917131427ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:201: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/coffea/nanoevents/schemas/nanoaod.py:201: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file_path = 'https://xrootd-local.unl.edu:1094//store/user/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19980_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext3-v1_00000_0000.root'\n",
    "tree_name = 'Events'\n",
    "# events = NanoEventsFactory.from_root({file_path: tree_name}, schemaclass=NanoAODSchema).events()\n",
    "events = NanoEventsFactory.from_root(file_path, treepath=tree_name, schemaclass=NanoAODSchema).events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb359e3-3f91-4f2a-b8ab-026a546a5b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#code from jetassignment_training\n",
    "# events filtering\n",
    "selected_electrons = events.Electron[(events.Electron.pt > 30) & (np.abs(events.Electron.eta)<2.1) & \n",
    "                                        (events.Electron.cutBased==4) & (events.Electron.sip3d < 4)]\n",
    "selected_muons = events.Muon[(events.Muon.pt > 30) & (np.abs(events.Muon.eta)<2.1) & (events.Muon.tightId) & \n",
    "                                (events.Muon.sip3d < 4) & (events.Muon.pfRelIso04_all < 0.15)]\n",
    "jet_filter = (events.Jet.pt > 30) & (np.abs(events.Jet.eta) < 2.4) & (events.Jet.isTightLeptonVeto)\n",
    "selected_jets = events.Jet[jet_filter]\n",
    "selected_genpart = events.GenPart\n",
    "even = (events.event%2==0)\n",
    "    \n",
    "# single lepton requirement\n",
    "event_filters = ((ak.count(selected_electrons.pt, axis=1) + ak.count(selected_muons.pt, axis=1)) == 1)\n",
    "# require at least 4 jets\n",
    "event_filters = event_filters & (ak.count(selected_jets.pt, axis=1) >= 4)\n",
    "# require at least one jet above B_TAG_THRESHOLD\n",
    "B_TAG_THRESHOLD = 0.5\n",
    "event_filters = event_filters & (ak.sum(selected_jets.btagCSVV2 >= B_TAG_THRESHOLD, axis=1) >= 1)\n",
    "    \n",
    "# apply event filters\n",
    "selected_electrons = selected_electrons[event_filters]\n",
    "selected_muons = selected_muons[event_filters]\n",
    "selected_jets = selected_jets[event_filters]\n",
    "selected_genpart = selected_genpart[event_filters]\n",
    "even = even[event_filters]\n",
    "    \n",
    "### only consider 4j2b (signal) region\n",
    "region_filter = ak.sum(selected_jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1) >= 2 # at least two b-tagged jets\n",
    "selected_jets_region = selected_jets[region_filter][:,:4] # only keep top 4 jets\n",
    "selected_electrons_region = selected_electrons[region_filter]\n",
    "selected_muons_region = selected_muons[region_filter]\n",
    "selected_genpart_region = selected_genpart[region_filter]\n",
    "even = even[region_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f31dd39-74af-4916-8bee-2762216861bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#don't need even\n",
    "jets, electrons, muons, labels, even = utils.ml.training_filter(selected_jets_region, \n",
    "                                                        selected_electrons_region, \n",
    "                                                        selected_muons_region, \n",
    "                                                        selected_genpart_region,\n",
    "                                                        even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf2c8f9-ff1b-4b57-bcff-a4e7f8e79e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jet_lepton_dR(jet_p4, lep_p4): #each event has 4 jets\n",
    "    dR_array = np.array([])\n",
    "    for event in range(len(jet_p4)):\n",
    "        dR = np.array([np.sqrt((lep_p4[event].eta - jet_p4[event,i].eta)**2 + (lep_p4[event].phi - jet_p4[event,i].phi)**2) for i in range(4)])\n",
    "        dR_array = np.append(dR_array, dR)\n",
    "    return dR_array\n",
    "\n",
    "\n",
    "def combinedMass(jet_p4, lep_p4):\n",
    "    mass_array = np.array([])\n",
    "    for event in range(len(jet_p4)):\n",
    "        mass = [lep_p4[event].mass + jet_p4[event].mass] #cant combine 4-vector before extracting mass, not sure if this is valud physically \n",
    "        mass_array = np.append(mass_array, mass)\n",
    "    return mass_array\n",
    "\n",
    "\n",
    "def array_to_tensor(array, chunk_size=1000, dtype=torch.float32):\n",
    "    # converting numpy.array into torch.tensor\n",
    "    # chunk iteration because of too many event\n",
    "    chunks_tensor = []\n",
    "    num_rows, num_col = array.shape\n",
    "    for row_start in range(0, num_rows, chunk_size):\n",
    "        row_end = min(row_start+chunk_size, num_rows)\n",
    "        small_array = array[row_start:row_end]\n",
    "        small_tensor = torch.tensor(small_array, dtype=torch.float32)\n",
    "        chunks_tensor.append(small_tensor)\n",
    "    return torch.cat(chunks_tensor, dim=0)\n",
    "\n",
    "# creating edge_indices for each event\n",
    "def sub_event_edge_indices(num_jets_in_event):\n",
    "    row = np.tile(np.arange(num_jets_in_event), num_jets_in_event)\n",
    "    col = np.repeat(np.arange(num_jets_in_event), num_jets_in_event)\n",
    "    #excluding edge with itself\n",
    "    mask = row != col\n",
    "    row = row[mask]\n",
    "    col = col[mask]\n",
    "    edge_idx = np.stack([row, col], axis=0)\n",
    "    return edge_idx\n",
    "\n",
    "# creating edge_indices for all event\n",
    "def full_edge_indices(num_jets_in_event, num_events):\n",
    "    edge_indices = []\n",
    "    offset = 0\n",
    "    for _ in range(num_events):\n",
    "        edge_index = sub_event_edge_indices(num_jets_in_event) #only jets in the same event are connected\n",
    "        edge_index += offset\n",
    "        edge_indices.append(edge_index)\n",
    "        offset += num_jets_in_event\n",
    "    concat_edge_indices = np.concatenate(edge_indices, axis=1)\n",
    "    return (array_to_tensor(concat_edge_indices.T).T).to(dtype=int) #the first T used for array_to_tensor, and another T to convert back to the original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "618fc4c4-3515-48e9-9558-cda94eff43de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "el_p4 = ak.zip({'pt': electrons.pt, 'eta': electrons.eta, 'phi': electrons.phi, 'mass': electrons.mass}, with_name= 'Momentum4D')\n",
    "mu_p4 = ak.zip({'pt': muons.pt, 'eta': muons.eta, 'phi': muons.phi, 'mass': muons.mass}, with_name= 'Momentum4D')\n",
    "lep_p4 = ak.concatenate((el_p4, mu_p4), axis=1)\n",
    "jet_p4 = ak.zip({'pt': jets.pt, 'eta': jets.eta, 'phi': jets.phi, 'mass': jets.mass}, with_name= 'Momentum4D')\n",
    "\n",
    "#node features from jets\n",
    "jet_pt = ak.flatten(jets.pt, axis=1).to_numpy()\n",
    "jet_mass = ak.flatten(jets.mass, axis=1).to_numpy()\n",
    "jet_phi = ak.flatten(jets.phi, axis=1).to_numpy()\n",
    "jet_eta = ak.flatten(jets.eta, axis=1).to_numpy()\n",
    "jet_btag = ak.flatten(jets.btagCSVV2, axis=1).to_numpy()\n",
    "jet_qgl = ak.flatten(jets.qgl, axis=1).to_numpy()\n",
    "# node features from jets+leptons\n",
    "jet_lep_dR = jet_lepton_dR(jet_p4, lep_p4)\n",
    "jet_lep_mass = combinedMass(jet_p4, lep_p4)\n",
    "\n",
    "# creating 2d array. Row is nodes (the total number of jets) with columns are features \n",
    "node_features = np.vstack((jet_pt, \n",
    "                           jet_mass,\n",
    "                           jet_phi, \n",
    "                           jet_eta, \n",
    "                           jet_btag, \n",
    "                           jet_qgl, \n",
    "                           jet_lep_dR, #dR between each jet and lepton (in the same event, 4 jets and 1 lepton)\n",
    "                           jet_lep_mass)).T #combined mass of each jet and lepton (in the same event, 4 jets and 1 lepton)\n",
    "\n",
    "# convert node_features_array to ninde_features_tensor\n",
    "node_features = array_to_tensor(node_features)\n",
    "\n",
    "# labels_tensor for jet assignment \n",
    "# need mapping {-6: 0, 6:1, 24:2} because loss_fn expect positive sequential labels\n",
    "label_map = {-6: 0, 6: 1, 24: 2}\n",
    "label_flatten = labels.flatten()\n",
    "transformed_labels = [label_map[label] for label in label_flatten]\n",
    "labels = torch.tensor(transformed_labels, dtype=torch.long)\n",
    "\n",
    "#edge_index_tensor\n",
    "num_events = ak.num(jets, axis=0)\n",
    "num_jets_in_event = 4\n",
    "edge_index = full_edge_indices(num_jets_in_event, num_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "865ac72b-7c2e-4253-8ad5-8de48f2f2be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25648, 8]), torch.Size([2, 76944]), torch.Size([25648]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.shape, edge_index.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9476eddc-ba27-4bed-b336-5eed5b04c9a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JetGraphDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, node_features, edge_index, labels):\n",
    "        self.node_features = node_features\n",
    "        self.edge_index = edge_index\n",
    "        self.labels = labels\n",
    "        self.num_events = len(labels)//4  # each event has 4 jets (// because must be integer)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_events #should this be the len of the whole nodes?\n",
    "    \n",
    "    def __getitem__(self, idx): #idx for each event\n",
    "        event_node_features = self.node_features[idx * 4:(idx + 1) * 4]  # moving through each event to get features\n",
    "        event_label = self.labels[idx * 4:(idx + 1) * 4]  # similarly but for labels\n",
    "        event_edge_index = self.edge_index[:, (self.edge_index[0] >= idx * 4) & (self.edge_index[0] < (idx + 1) * 4)]# extracting edge_index for each event\n",
    "        event_edge_index = event_edge_index - idx * 4  # Reindex for this event\n",
    "        data = Data(x=event_node_features, edge_index=event_edge_index, y=event_label)\n",
    "        return data\n",
    "\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_labels, num_heads, dropout):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, hidden_dim, heads=num_heads, dropout=dropout)\n",
    "        self.conv2 = GATConv(hidden_dim * num_heads, hidden_dim, heads=num_heads, dropout=dropout)\n",
    "        self.conv3 = GATConv(hidden_dim * num_heads, num_labels, heads=1, concat=True, dropout=dropout)\n",
    "        self.dropout = torch.nn.Dropout(p=0.6)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # x, edge_index = data.x, data.edge_index\n",
    "        # First GAT layer\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        # Second GAT layer (optional)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        # last layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return F.softmax(x, dim=1) #F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_loader, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.x, data.edge_index)\n",
    "            loss = loss_fn(output, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Train Epoch: [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            output = model(data.x, data.edge_index)\n",
    "            _, predicted = torch.max(output.data, 1) #check the intermediat output (checking the argument)\n",
    "            total += data.y.size(0)\n",
    "            correct += (predicted == data.y).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b5951-d06d-4a80-8b8b-9eac8a1fde93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a4e04-62a5-43ba-8ba4-b29bfa1cc69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a5715ef-7e6e-49e3-854b-0b1ddd52339e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: [1/100], Loss: 1.0870\n",
      "Train Epoch: [2/100], Loss: 1.0488\n",
      "Train Epoch: [3/100], Loss: 1.0467\n",
      "Train Epoch: [4/100], Loss: 1.0465\n",
      "Train Epoch: [5/100], Loss: 1.0452\n",
      "Train Epoch: [6/100], Loss: 1.0466\n",
      "Train Epoch: [7/100], Loss: 1.0471\n",
      "Train Epoch: [8/100], Loss: 1.0460\n",
      "Train Epoch: [9/100], Loss: 1.0448\n",
      "Train Epoch: [10/100], Loss: 1.0448\n",
      "Train Epoch: [11/100], Loss: 1.0457\n",
      "Train Epoch: [12/100], Loss: 1.0467\n",
      "Train Epoch: [13/100], Loss: 1.0493\n",
      "Train Epoch: [14/100], Loss: 1.0464\n",
      "Train Epoch: [15/100], Loss: 1.0460\n",
      "Train Epoch: [16/100], Loss: 1.0471\n",
      "Train Epoch: [17/100], Loss: 1.0461\n",
      "Train Epoch: [18/100], Loss: 1.0463\n",
      "Train Epoch: [19/100], Loss: 1.0459\n",
      "Train Epoch: [20/100], Loss: 1.0459\n",
      "Train Epoch: [21/100], Loss: 1.0452\n",
      "Train Epoch: [22/100], Loss: 1.0460\n",
      "Train Epoch: [23/100], Loss: 1.0458\n",
      "Train Epoch: [24/100], Loss: 1.0466\n",
      "Train Epoch: [25/100], Loss: 1.0477\n",
      "Train Epoch: [26/100], Loss: 1.0490\n",
      "Train Epoch: [27/100], Loss: 1.0492\n",
      "Train Epoch: [28/100], Loss: 1.0471\n",
      "Train Epoch: [29/100], Loss: 1.0468\n",
      "Train Epoch: [30/100], Loss: 1.0460\n",
      "Train Epoch: [31/100], Loss: 1.0455\n",
      "Train Epoch: [32/100], Loss: 1.0454\n",
      "Train Epoch: [33/100], Loss: 1.0456\n",
      "Train Epoch: [34/100], Loss: 1.0456\n",
      "Train Epoch: [35/100], Loss: 1.0433\n",
      "Train Epoch: [36/100], Loss: 1.0453\n",
      "Train Epoch: [37/100], Loss: 1.0451\n",
      "Train Epoch: [38/100], Loss: 1.0456\n",
      "Train Epoch: [39/100], Loss: 1.0444\n",
      "Train Epoch: [40/100], Loss: 1.0441\n",
      "Train Epoch: [41/100], Loss: 1.0455\n",
      "Train Epoch: [42/100], Loss: 1.0450\n",
      "Train Epoch: [43/100], Loss: 1.0454\n",
      "Train Epoch: [44/100], Loss: 1.0456\n",
      "Train Epoch: [45/100], Loss: 1.0446\n",
      "Train Epoch: [46/100], Loss: 1.0446\n",
      "Train Epoch: [47/100], Loss: 1.0452\n",
      "Train Epoch: [48/100], Loss: 1.0454\n",
      "Train Epoch: [49/100], Loss: 1.0445\n",
      "Train Epoch: [50/100], Loss: 1.0446\n",
      "Train Epoch: [51/100], Loss: 1.0450\n",
      "Train Epoch: [52/100], Loss: 1.0440\n",
      "Train Epoch: [53/100], Loss: 1.0440\n",
      "Train Epoch: [54/100], Loss: 1.0442\n",
      "Train Epoch: [55/100], Loss: 1.0448\n",
      "Train Epoch: [56/100], Loss: 1.0447\n",
      "Train Epoch: [57/100], Loss: 1.0452\n",
      "Train Epoch: [58/100], Loss: 1.0448\n",
      "Train Epoch: [59/100], Loss: 1.0438\n",
      "Train Epoch: [60/100], Loss: 1.0449\n",
      "Train Epoch: [61/100], Loss: 1.0441\n",
      "Train Epoch: [62/100], Loss: 1.0445\n",
      "Train Epoch: [63/100], Loss: 1.0446\n",
      "Train Epoch: [64/100], Loss: 1.0445\n",
      "Train Epoch: [65/100], Loss: 1.0447\n",
      "Train Epoch: [66/100], Loss: 1.0440\n",
      "Train Epoch: [67/100], Loss: 1.0444\n",
      "Train Epoch: [68/100], Loss: 1.0452\n",
      "Train Epoch: [69/100], Loss: 1.0451\n",
      "Train Epoch: [70/100], Loss: 1.0441\n",
      "Train Epoch: [71/100], Loss: 1.0448\n",
      "Train Epoch: [72/100], Loss: 1.0452\n",
      "Train Epoch: [73/100], Loss: 1.0457\n",
      "Train Epoch: [74/100], Loss: 1.0455\n",
      "Train Epoch: [75/100], Loss: 1.0444\n",
      "Train Epoch: [76/100], Loss: 1.0445\n",
      "Train Epoch: [77/100], Loss: 1.0448\n",
      "Train Epoch: [78/100], Loss: 1.0456\n",
      "Train Epoch: [79/100], Loss: 1.0477\n",
      "Train Epoch: [80/100], Loss: 1.0452\n",
      "Train Epoch: [81/100], Loss: 1.0451\n",
      "Train Epoch: [82/100], Loss: 1.0459\n",
      "Train Epoch: [83/100], Loss: 1.0472\n",
      "Train Epoch: [84/100], Loss: 1.0459\n",
      "Train Epoch: [85/100], Loss: 1.0480\n",
      "Train Epoch: [86/100], Loss: 1.0459\n",
      "Train Epoch: [87/100], Loss: 1.0465\n",
      "Train Epoch: [88/100], Loss: 1.0456\n",
      "Train Epoch: [89/100], Loss: 1.0452\n",
      "Train Epoch: [90/100], Loss: 1.0442\n",
      "Train Epoch: [91/100], Loss: 1.0445\n",
      "Train Epoch: [92/100], Loss: 1.0447\n",
      "Train Epoch: [93/100], Loss: 1.0462\n",
      "Train Epoch: [94/100], Loss: 1.0452\n",
      "Train Epoch: [95/100], Loss: 1.0460\n",
      "Train Epoch: [96/100], Loss: 1.0468\n",
      "Train Epoch: [97/100], Loss: 1.0451\n",
      "Train Epoch: [98/100], Loss: 1.0451\n",
      "Train Epoch: [99/100], Loss: 1.0455\n",
      "Train Epoch: [100/100], Loss: 1.0462\n",
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# normal training without cross-validation\n",
    "# Create dataset\n",
    "dataset = JetGraphDataset(node_features, edge_index, labels)\n",
    "\n",
    "# Split dataset into training and testing\n",
    "train_idx, test_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = DataLoader(dataset, sampler=train_sampler, batch_size=32)\n",
    "test_loader = DataLoader(dataset, sampler=test_sampler, batch_size=32)\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "num_features = node_features.shape[1]\n",
    "hidden_dim = 8 #64\n",
    "# num_labels = 4 # actually 3 (-6, 6, 24)\n",
    "num_labels = 3\n",
    "num_heads = 8 #8\n",
    "dropout = 0.6\n",
    "lr = 0.005\n",
    "weight_decay = 5e-4\n",
    "epochs = 100\n",
    "\n",
    "model = GATModel(num_features, hidden_dim, num_labels, num_heads, dropout)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Train and test the model\n",
    "train(model, optimizer, loss_fn, train_loader, epochs=epochs)\n",
    "accuracy = test(model, test_loader)\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892ac599-d7d6-448c-81a9-863e8ea3ce0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Train Epoch: [1/100], Loss: 1.1061\n",
      "Train Epoch: [2/100], Loss: 1.0644\n",
      "Train Epoch: [3/100], Loss: 1.0583\n",
      "Train Epoch: [4/100], Loss: 1.0507\n",
      "Train Epoch: [5/100], Loss: 1.0480\n",
      "Train Epoch: [6/100], Loss: 1.0519\n",
      "Train Epoch: [7/100], Loss: 1.0491\n",
      "Train Epoch: [8/100], Loss: 1.0478\n",
      "Train Epoch: [9/100], Loss: 1.0475\n",
      "Train Epoch: [10/100], Loss: 1.0469\n",
      "Train Epoch: [11/100], Loss: 1.0475\n",
      "Train Epoch: [12/100], Loss: 1.0470\n",
      "Train Epoch: [13/100], Loss: 1.0474\n",
      "Train Epoch: [14/100], Loss: 1.0449\n",
      "Train Epoch: [15/100], Loss: 1.0440\n",
      "Train Epoch: [16/100], Loss: 1.0464\n",
      "Train Epoch: [17/100], Loss: 1.0456\n",
      "Train Epoch: [18/100], Loss: 1.0481\n",
      "Train Epoch: [19/100], Loss: 1.0482\n",
      "Train Epoch: [20/100], Loss: 1.0494\n",
      "Train Epoch: [21/100], Loss: 1.0470\n",
      "Train Epoch: [22/100], Loss: 1.0467\n",
      "Train Epoch: [23/100], Loss: 1.0460\n",
      "Train Epoch: [24/100], Loss: 1.0487\n",
      "Train Epoch: [25/100], Loss: 1.0475\n",
      "Train Epoch: [26/100], Loss: 1.0461\n",
      "Train Epoch: [27/100], Loss: 1.0467\n",
      "Train Epoch: [28/100], Loss: 1.0478\n",
      "Train Epoch: [29/100], Loss: 1.0461\n",
      "Train Epoch: [30/100], Loss: 1.0460\n",
      "Train Epoch: [31/100], Loss: 1.0451\n",
      "Train Epoch: [32/100], Loss: 1.0434\n",
      "Train Epoch: [33/100], Loss: 1.0459\n",
      "Train Epoch: [34/100], Loss: 1.0425\n",
      "Train Epoch: [35/100], Loss: 1.0442\n",
      "Train Epoch: [36/100], Loss: 1.0467\n",
      "Train Epoch: [37/100], Loss: 1.0469\n",
      "Train Epoch: [38/100], Loss: 1.0457\n",
      "Train Epoch: [39/100], Loss: 1.0459\n",
      "Train Epoch: [40/100], Loss: 1.0465\n",
      "Train Epoch: [41/100], Loss: 1.0456\n",
      "Train Epoch: [42/100], Loss: 1.0457\n",
      "Train Epoch: [43/100], Loss: 1.0475\n",
      "Train Epoch: [44/100], Loss: 1.0467\n",
      "Train Epoch: [45/100], Loss: 1.0468\n",
      "Train Epoch: [46/100], Loss: 1.0460\n",
      "Train Epoch: [47/100], Loss: 1.0466\n",
      "Train Epoch: [48/100], Loss: 1.0478\n",
      "Train Epoch: [49/100], Loss: 1.0492\n",
      "Train Epoch: [50/100], Loss: 1.0485\n",
      "Train Epoch: [51/100], Loss: 1.0465\n",
      "Train Epoch: [52/100], Loss: 1.0482\n",
      "Train Epoch: [53/100], Loss: 1.0493\n",
      "Train Epoch: [54/100], Loss: 1.0511\n",
      "Train Epoch: [55/100], Loss: 1.0496\n",
      "Train Epoch: [56/100], Loss: 1.0475\n",
      "Train Epoch: [57/100], Loss: 1.0483\n",
      "Train Epoch: [58/100], Loss: 1.0502\n",
      "Train Epoch: [59/100], Loss: 1.0497\n",
      "Train Epoch: [60/100], Loss: 1.0484\n",
      "Train Epoch: [61/100], Loss: 1.0475\n",
      "Train Epoch: [62/100], Loss: 1.0491\n",
      "Train Epoch: [63/100], Loss: 1.0464\n",
      "Train Epoch: [64/100], Loss: 1.0471\n",
      "Train Epoch: [65/100], Loss: 1.0460\n",
      "Train Epoch: [66/100], Loss: 1.0470\n",
      "Train Epoch: [67/100], Loss: 1.0454\n",
      "Train Epoch: [68/100], Loss: 1.0502\n",
      "Train Epoch: [69/100], Loss: 1.0472\n",
      "Train Epoch: [70/100], Loss: 1.0467\n",
      "Train Epoch: [71/100], Loss: 1.0486\n",
      "Train Epoch: [72/100], Loss: 1.0475\n",
      "Train Epoch: [73/100], Loss: 1.0492\n",
      "Train Epoch: [74/100], Loss: 1.0478\n",
      "Train Epoch: [75/100], Loss: 1.0482\n",
      "Train Epoch: [76/100], Loss: 1.0479\n",
      "Train Epoch: [77/100], Loss: 1.0469\n",
      "Train Epoch: [78/100], Loss: 1.0480\n",
      "Train Epoch: [79/100], Loss: 1.0475\n",
      "Train Epoch: [80/100], Loss: 1.0458\n",
      "Train Epoch: [81/100], Loss: 1.0486\n",
      "Train Epoch: [82/100], Loss: 1.0454\n",
      "Train Epoch: [83/100], Loss: 1.0475\n",
      "Train Epoch: [84/100], Loss: 1.0479\n",
      "Train Epoch: [85/100], Loss: 1.0507\n",
      "Train Epoch: [86/100], Loss: 1.0504\n",
      "Train Epoch: [87/100], Loss: 1.0482\n",
      "Train Epoch: [88/100], Loss: 1.0483\n",
      "Train Epoch: [89/100], Loss: 1.0467\n",
      "Train Epoch: [90/100], Loss: 1.0472\n",
      "Train Epoch: [91/100], Loss: 1.0477\n",
      "Train Epoch: [92/100], Loss: 1.0486\n",
      "Train Epoch: [93/100], Loss: 1.0483\n",
      "Train Epoch: [94/100], Loss: 1.0498\n",
      "Train Epoch: [95/100], Loss: 1.0453\n",
      "Train Epoch: [96/100], Loss: 1.0459\n",
      "Train Epoch: [97/100], Loss: 1.0477\n",
      "Train Epoch: [98/100], Loss: 1.0456\n",
      "Train Epoch: [99/100], Loss: 1.0485\n",
      "Train Epoch: [100/100], Loss: 1.0467\n",
      "Fold 1 - Test Accuracy: 49.81%\n",
      "Fold 2/5\n",
      "Train Epoch: [1/100], Loss: 1.0765\n",
      "Train Epoch: [2/100], Loss: 1.0540\n",
      "Train Epoch: [3/100], Loss: 1.0510\n",
      "Train Epoch: [4/100], Loss: 1.0552\n",
      "Train Epoch: [5/100], Loss: 1.0453\n",
      "Train Epoch: [6/100], Loss: 1.0469\n",
      "Train Epoch: [7/100], Loss: 1.0446\n",
      "Train Epoch: [8/100], Loss: 1.0452\n",
      "Train Epoch: [9/100], Loss: 1.0445\n",
      "Train Epoch: [10/100], Loss: 1.0431\n",
      "Train Epoch: [11/100], Loss: 1.0463\n",
      "Train Epoch: [12/100], Loss: 1.0455\n",
      "Train Epoch: [13/100], Loss: 1.0446\n",
      "Train Epoch: [14/100], Loss: 1.0453\n",
      "Train Epoch: [15/100], Loss: 1.0545\n",
      "Train Epoch: [16/100], Loss: 1.0579\n",
      "Train Epoch: [17/100], Loss: 1.0521\n",
      "Train Epoch: [18/100], Loss: 1.0495\n",
      "Train Epoch: [19/100], Loss: 1.0520\n",
      "Train Epoch: [20/100], Loss: 1.0493\n",
      "Train Epoch: [21/100], Loss: 1.0493\n",
      "Train Epoch: [22/100], Loss: 1.0495\n",
      "Train Epoch: [23/100], Loss: 1.0468\n",
      "Train Epoch: [24/100], Loss: 1.0476\n",
      "Train Epoch: [25/100], Loss: 1.0465\n",
      "Train Epoch: [26/100], Loss: 1.0465\n",
      "Train Epoch: [27/100], Loss: 1.0478\n",
      "Train Epoch: [28/100], Loss: 1.0468\n",
      "Train Epoch: [29/100], Loss: 1.0449\n",
      "Train Epoch: [30/100], Loss: 1.0441\n",
      "Train Epoch: [31/100], Loss: 1.0443\n",
      "Train Epoch: [32/100], Loss: 1.0460\n",
      "Train Epoch: [33/100], Loss: 1.0444\n",
      "Train Epoch: [34/100], Loss: 1.0427\n",
      "Train Epoch: [35/100], Loss: 1.0437\n",
      "Train Epoch: [36/100], Loss: 1.0446\n",
      "Train Epoch: [37/100], Loss: 1.0436\n",
      "Train Epoch: [38/100], Loss: 1.0437\n",
      "Train Epoch: [39/100], Loss: 1.0459\n",
      "Train Epoch: [40/100], Loss: 1.0429\n",
      "Train Epoch: [41/100], Loss: 1.0446\n",
      "Train Epoch: [42/100], Loss: 1.0445\n",
      "Train Epoch: [43/100], Loss: 1.0440\n",
      "Train Epoch: [44/100], Loss: 1.0434\n",
      "Train Epoch: [45/100], Loss: 1.0445\n",
      "Train Epoch: [46/100], Loss: 1.0473\n",
      "Train Epoch: [47/100], Loss: 1.0461\n",
      "Train Epoch: [48/100], Loss: 1.0447\n",
      "Train Epoch: [49/100], Loss: 1.0443\n",
      "Train Epoch: [50/100], Loss: 1.0471\n",
      "Train Epoch: [51/100], Loss: 1.0455\n",
      "Train Epoch: [52/100], Loss: 1.0447\n",
      "Train Epoch: [53/100], Loss: 1.0456\n",
      "Train Epoch: [54/100], Loss: 1.0461\n",
      "Train Epoch: [55/100], Loss: 1.0452\n",
      "Train Epoch: [56/100], Loss: 1.0459\n",
      "Train Epoch: [57/100], Loss: 1.0482\n",
      "Train Epoch: [58/100], Loss: 1.0456\n",
      "Train Epoch: [59/100], Loss: 1.0438\n",
      "Train Epoch: [60/100], Loss: 1.0467\n",
      "Train Epoch: [61/100], Loss: 1.0453\n",
      "Train Epoch: [62/100], Loss: 1.0451\n",
      "Train Epoch: [63/100], Loss: 1.0453\n",
      "Train Epoch: [64/100], Loss: 1.0450\n",
      "Train Epoch: [65/100], Loss: 1.0449\n",
      "Train Epoch: [66/100], Loss: 1.0435\n",
      "Train Epoch: [67/100], Loss: 1.0444\n",
      "Train Epoch: [68/100], Loss: 1.0457\n",
      "Train Epoch: [69/100], Loss: 1.0468\n",
      "Train Epoch: [70/100], Loss: 1.0466\n",
      "Train Epoch: [71/100], Loss: 1.0464\n",
      "Train Epoch: [72/100], Loss: 1.0462\n",
      "Train Epoch: [73/100], Loss: 1.0486\n",
      "Train Epoch: [74/100], Loss: 1.0474\n",
      "Train Epoch: [75/100], Loss: 1.0470\n",
      "Train Epoch: [76/100], Loss: 1.0445\n",
      "Train Epoch: [77/100], Loss: 1.0470\n",
      "Train Epoch: [78/100], Loss: 1.0473\n",
      "Train Epoch: [79/100], Loss: 1.0465\n",
      "Train Epoch: [80/100], Loss: 1.0451\n",
      "Train Epoch: [81/100], Loss: 1.0467\n",
      "Train Epoch: [82/100], Loss: 1.0465\n",
      "Train Epoch: [83/100], Loss: 1.0473\n",
      "Train Epoch: [84/100], Loss: 1.0464\n",
      "Train Epoch: [85/100], Loss: 1.0472\n",
      "Train Epoch: [86/100], Loss: 1.0469\n",
      "Train Epoch: [87/100], Loss: 1.0484\n",
      "Train Epoch: [88/100], Loss: 1.0474\n",
      "Train Epoch: [89/100], Loss: 1.0468\n",
      "Train Epoch: [90/100], Loss: 1.0483\n",
      "Train Epoch: [91/100], Loss: 1.0472\n",
      "Train Epoch: [92/100], Loss: 1.0470\n",
      "Train Epoch: [93/100], Loss: 1.0460\n",
      "Train Epoch: [94/100], Loss: 1.0472\n",
      "Train Epoch: [95/100], Loss: 1.0456\n",
      "Train Epoch: [96/100], Loss: 1.0443\n",
      "Train Epoch: [97/100], Loss: 1.0444\n",
      "Train Epoch: [98/100], Loss: 1.0454\n",
      "Train Epoch: [99/100], Loss: 1.0444\n",
      "Train Epoch: [100/100], Loss: 1.0463\n",
      "Fold 2 - Test Accuracy: 49.49%\n",
      "Fold 3/5\n",
      "Train Epoch: [1/100], Loss: 1.1069\n",
      "Train Epoch: [2/100], Loss: 1.0585\n",
      "Train Epoch: [3/100], Loss: 1.0508\n",
      "Train Epoch: [4/100], Loss: 1.0463\n",
      "Train Epoch: [5/100], Loss: 1.0483\n",
      "Train Epoch: [6/100], Loss: 1.0563\n",
      "Train Epoch: [7/100], Loss: 1.0653\n",
      "Train Epoch: [8/100], Loss: 1.0500\n",
      "Train Epoch: [9/100], Loss: 1.0463\n",
      "Train Epoch: [10/100], Loss: 1.0456\n",
      "Train Epoch: [11/100], Loss: 1.0469\n",
      "Train Epoch: [12/100], Loss: 1.0464\n",
      "Train Epoch: [13/100], Loss: 1.0497\n",
      "Train Epoch: [14/100], Loss: 1.0450\n",
      "Train Epoch: [15/100], Loss: 1.0463\n",
      "Train Epoch: [16/100], Loss: 1.0465\n",
      "Train Epoch: [17/100], Loss: 1.0448\n",
      "Train Epoch: [18/100], Loss: 1.0473\n",
      "Train Epoch: [19/100], Loss: 1.0447\n",
      "Train Epoch: [20/100], Loss: 1.0459\n",
      "Train Epoch: [21/100], Loss: 1.0477\n",
      "Train Epoch: [22/100], Loss: 1.0488\n",
      "Train Epoch: [23/100], Loss: 1.0467\n",
      "Train Epoch: [24/100], Loss: 1.0506\n",
      "Train Epoch: [25/100], Loss: 1.0481\n",
      "Train Epoch: [26/100], Loss: 1.0516\n",
      "Train Epoch: [27/100], Loss: 1.0526\n",
      "Train Epoch: [28/100], Loss: 1.0592\n",
      "Train Epoch: [29/100], Loss: 1.0491\n",
      "Train Epoch: [30/100], Loss: 1.0469\n",
      "Train Epoch: [31/100], Loss: 1.0466\n",
      "Train Epoch: [32/100], Loss: 1.0463\n",
      "Train Epoch: [33/100], Loss: 1.0451\n",
      "Train Epoch: [34/100], Loss: 1.0447\n",
      "Train Epoch: [35/100], Loss: 1.0441\n",
      "Train Epoch: [36/100], Loss: 1.0465\n",
      "Train Epoch: [37/100], Loss: 1.0443\n",
      "Train Epoch: [38/100], Loss: 1.0440\n",
      "Train Epoch: [39/100], Loss: 1.0439\n",
      "Train Epoch: [40/100], Loss: 1.0441\n",
      "Train Epoch: [41/100], Loss: 1.0448\n",
      "Train Epoch: [42/100], Loss: 1.0444\n",
      "Train Epoch: [43/100], Loss: 1.0454\n",
      "Train Epoch: [44/100], Loss: 1.0455\n",
      "Train Epoch: [45/100], Loss: 1.0462\n",
      "Train Epoch: [46/100], Loss: 1.0453\n",
      "Train Epoch: [47/100], Loss: 1.0477\n",
      "Train Epoch: [48/100], Loss: 1.0453\n",
      "Train Epoch: [49/100], Loss: 1.0505\n",
      "Train Epoch: [50/100], Loss: 1.0495\n",
      "Train Epoch: [51/100], Loss: 1.0491\n",
      "Train Epoch: [52/100], Loss: 1.0481\n",
      "Train Epoch: [53/100], Loss: 1.0504\n",
      "Train Epoch: [54/100], Loss: 1.0483\n",
      "Train Epoch: [55/100], Loss: 1.0464\n",
      "Train Epoch: [56/100], Loss: 1.0504\n",
      "Train Epoch: [57/100], Loss: 1.0517\n",
      "Train Epoch: [58/100], Loss: 1.0467\n",
      "Train Epoch: [59/100], Loss: 1.0496\n",
      "Train Epoch: [60/100], Loss: 1.0481\n",
      "Train Epoch: [61/100], Loss: 1.0467\n",
      "Train Epoch: [62/100], Loss: 1.0460\n",
      "Train Epoch: [63/100], Loss: 1.0479\n",
      "Train Epoch: [64/100], Loss: 1.0489\n",
      "Train Epoch: [65/100], Loss: 1.0465\n",
      "Train Epoch: [66/100], Loss: 1.0485\n",
      "Train Epoch: [67/100], Loss: 1.0523\n",
      "Train Epoch: [68/100], Loss: 1.0464\n",
      "Train Epoch: [69/100], Loss: 1.0451\n",
      "Train Epoch: [70/100], Loss: 1.0505\n",
      "Train Epoch: [71/100], Loss: 1.0481\n",
      "Train Epoch: [72/100], Loss: 1.0475\n",
      "Train Epoch: [73/100], Loss: 1.0462\n",
      "Train Epoch: [74/100], Loss: 1.0466\n",
      "Train Epoch: [75/100], Loss: 1.0482\n",
      "Train Epoch: [76/100], Loss: 1.0477\n",
      "Train Epoch: [77/100], Loss: 1.0485\n",
      "Train Epoch: [78/100], Loss: 1.0482\n",
      "Train Epoch: [79/100], Loss: 1.0463\n",
      "Train Epoch: [80/100], Loss: 1.0478\n",
      "Train Epoch: [81/100], Loss: 1.0472\n",
      "Train Epoch: [82/100], Loss: 1.0464\n",
      "Train Epoch: [83/100], Loss: 1.0454\n",
      "Train Epoch: [84/100], Loss: 1.0487\n",
      "Train Epoch: [85/100], Loss: 1.0472\n",
      "Train Epoch: [86/100], Loss: 1.0466\n",
      "Train Epoch: [87/100], Loss: 1.0500\n",
      "Train Epoch: [88/100], Loss: 1.0445\n",
      "Train Epoch: [89/100], Loss: 1.0474\n",
      "Train Epoch: [90/100], Loss: 1.0453\n",
      "Train Epoch: [91/100], Loss: 1.0458\n",
      "Train Epoch: [92/100], Loss: 1.0454\n",
      "Train Epoch: [93/100], Loss: 1.0447\n",
      "Train Epoch: [94/100], Loss: 1.0444\n",
      "Train Epoch: [95/100], Loss: 1.0441\n",
      "Train Epoch: [96/100], Loss: 1.0466\n",
      "Train Epoch: [97/100], Loss: 1.0461\n",
      "Train Epoch: [98/100], Loss: 1.0429\n",
      "Train Epoch: [99/100], Loss: 1.0451\n",
      "Train Epoch: [100/100], Loss: 1.0447\n",
      "Fold 3 - Test Accuracy: 49.69%\n",
      "Fold 4/5\n",
      "Train Epoch: [1/100], Loss: 1.0931\n",
      "Train Epoch: [2/100], Loss: 1.0727\n",
      "Train Epoch: [3/100], Loss: 1.0677\n",
      "Train Epoch: [4/100], Loss: 1.0685\n",
      "Train Epoch: [5/100], Loss: 1.0608\n",
      "Train Epoch: [6/100], Loss: 1.0573\n",
      "Train Epoch: [7/100], Loss: 1.0575\n",
      "Train Epoch: [8/100], Loss: 1.0574\n",
      "Train Epoch: [9/100], Loss: 1.0726\n",
      "Train Epoch: [10/100], Loss: 1.0664\n",
      "Train Epoch: [11/100], Loss: 1.0708\n",
      "Train Epoch: [12/100], Loss: 1.0633\n",
      "Train Epoch: [13/100], Loss: 1.0719\n",
      "Train Epoch: [14/100], Loss: 1.0761\n",
      "Train Epoch: [15/100], Loss: 1.0820\n",
      "Train Epoch: [16/100], Loss: 1.0860\n",
      "Train Epoch: [17/100], Loss: 1.0716\n",
      "Train Epoch: [18/100], Loss: 1.0774\n",
      "Train Epoch: [19/100], Loss: 1.0885\n",
      "Train Epoch: [20/100], Loss: 1.0835\n",
      "Train Epoch: [21/100], Loss: 1.0902\n",
      "Train Epoch: [22/100], Loss: 1.0852\n",
      "Train Epoch: [23/100], Loss: 1.0781\n",
      "Train Epoch: [24/100], Loss: 1.0728\n",
      "Train Epoch: [25/100], Loss: 1.0632\n",
      "Train Epoch: [26/100], Loss: 1.0622\n",
      "Train Epoch: [27/100], Loss: 1.0626\n",
      "Train Epoch: [28/100], Loss: 1.0631\n",
      "Train Epoch: [29/100], Loss: 1.0621\n",
      "Train Epoch: [30/100], Loss: 1.0707\n",
      "Train Epoch: [31/100], Loss: 1.0751\n",
      "Train Epoch: [32/100], Loss: 1.0681\n",
      "Train Epoch: [33/100], Loss: 1.0616\n",
      "Train Epoch: [34/100], Loss: 1.0536\n",
      "Train Epoch: [35/100], Loss: 1.0529\n",
      "Train Epoch: [36/100], Loss: 1.0560\n",
      "Train Epoch: [37/100], Loss: 1.0544\n",
      "Train Epoch: [38/100], Loss: 1.0533\n",
      "Train Epoch: [39/100], Loss: 1.0513\n",
      "Train Epoch: [40/100], Loss: 1.0521\n",
      "Train Epoch: [41/100], Loss: 1.0487\n",
      "Train Epoch: [42/100], Loss: 1.0468\n",
      "Train Epoch: [43/100], Loss: 1.0469\n",
      "Train Epoch: [44/100], Loss: 1.0482\n",
      "Train Epoch: [45/100], Loss: 1.0497\n",
      "Train Epoch: [46/100], Loss: 1.0509\n",
      "Train Epoch: [47/100], Loss: 1.0498\n",
      "Train Epoch: [48/100], Loss: 1.0465\n",
      "Train Epoch: [49/100], Loss: 1.0475\n",
      "Train Epoch: [50/100], Loss: 1.0452\n",
      "Train Epoch: [51/100], Loss: 1.0477\n",
      "Train Epoch: [52/100], Loss: 1.0472\n",
      "Train Epoch: [53/100], Loss: 1.0465\n",
      "Train Epoch: [54/100], Loss: 1.0482\n",
      "Train Epoch: [55/100], Loss: 1.0466\n",
      "Train Epoch: [56/100], Loss: 1.0464\n",
      "Train Epoch: [57/100], Loss: 1.0522\n",
      "Train Epoch: [58/100], Loss: 1.0520\n",
      "Train Epoch: [59/100], Loss: 1.0529\n",
      "Train Epoch: [60/100], Loss: 1.0495\n",
      "Train Epoch: [61/100], Loss: 1.0528\n",
      "Train Epoch: [62/100], Loss: 1.0494\n",
      "Train Epoch: [63/100], Loss: 1.0492\n",
      "Train Epoch: [64/100], Loss: 1.0499\n",
      "Train Epoch: [65/100], Loss: 1.0503\n",
      "Train Epoch: [66/100], Loss: 1.0504\n",
      "Train Epoch: [67/100], Loss: 1.0502\n",
      "Train Epoch: [68/100], Loss: 1.0501\n",
      "Train Epoch: [69/100], Loss: 1.0504\n",
      "Train Epoch: [70/100], Loss: 1.0498\n",
      "Train Epoch: [71/100], Loss: 1.0550\n",
      "Train Epoch: [72/100], Loss: 1.0536\n",
      "Train Epoch: [73/100], Loss: 1.0538\n",
      "Train Epoch: [74/100], Loss: 1.0582\n",
      "Train Epoch: [75/100], Loss: 1.0545\n",
      "Train Epoch: [76/100], Loss: 1.0511\n",
      "Train Epoch: [77/100], Loss: 1.0519\n",
      "Train Epoch: [78/100], Loss: 1.0542\n",
      "Train Epoch: [79/100], Loss: 1.0482\n",
      "Train Epoch: [80/100], Loss: 1.0496\n",
      "Train Epoch: [81/100], Loss: 1.0503\n",
      "Train Epoch: [82/100], Loss: 1.0484\n",
      "Train Epoch: [83/100], Loss: 1.0474\n",
      "Train Epoch: [84/100], Loss: 1.0485\n",
      "Train Epoch: [85/100], Loss: 1.0508\n",
      "Train Epoch: [86/100], Loss: 1.0515\n",
      "Train Epoch: [87/100], Loss: 1.0496\n",
      "Train Epoch: [88/100], Loss: 1.0529\n",
      "Train Epoch: [89/100], Loss: 1.0527\n",
      "Train Epoch: [90/100], Loss: 1.0547\n",
      "Train Epoch: [91/100], Loss: 1.0591\n",
      "Train Epoch: [92/100], Loss: 1.0614\n",
      "Train Epoch: [93/100], Loss: 1.0615\n",
      "Train Epoch: [94/100], Loss: 1.0594\n",
      "Train Epoch: [95/100], Loss: 1.0602\n",
      "Train Epoch: [96/100], Loss: 1.0586\n",
      "Train Epoch: [97/100], Loss: 1.0552\n",
      "Train Epoch: [98/100], Loss: 1.0467\n",
      "Train Epoch: [99/100], Loss: 1.0490\n",
      "Train Epoch: [100/100], Loss: 1.0487\n",
      "Fold 4 - Test Accuracy: 50.62%\n",
      "Fold 5/5\n",
      "Train Epoch: [1/100], Loss: 1.0961\n",
      "Train Epoch: [2/100], Loss: 1.0602\n",
      "Train Epoch: [3/100], Loss: 1.0878\n",
      "Train Epoch: [4/100], Loss: 1.1004\n",
      "Train Epoch: [5/100], Loss: 1.0691\n",
      "Train Epoch: [6/100], Loss: 1.0605\n",
      "Train Epoch: [7/100], Loss: 1.0572\n",
      "Train Epoch: [8/100], Loss: 1.0593\n",
      "Train Epoch: [9/100], Loss: 1.0599\n",
      "Train Epoch: [10/100], Loss: 1.0558\n",
      "Train Epoch: [11/100], Loss: 1.0526\n",
      "Train Epoch: [12/100], Loss: 1.0546\n",
      "Train Epoch: [13/100], Loss: 1.0557\n",
      "Train Epoch: [14/100], Loss: 1.0525\n",
      "Train Epoch: [15/100], Loss: 1.0523\n",
      "Train Epoch: [16/100], Loss: 1.0515\n",
      "Train Epoch: [17/100], Loss: 1.0566\n",
      "Train Epoch: [18/100], Loss: 1.0572\n",
      "Train Epoch: [19/100], Loss: 1.0638\n",
      "Train Epoch: [20/100], Loss: 1.0671\n",
      "Train Epoch: [21/100], Loss: 1.0573\n",
      "Train Epoch: [22/100], Loss: 1.0562\n",
      "Train Epoch: [23/100], Loss: 1.0558\n",
      "Train Epoch: [24/100], Loss: 1.0561\n",
      "Train Epoch: [25/100], Loss: 1.0554\n",
      "Train Epoch: [26/100], Loss: 1.0531\n",
      "Train Epoch: [27/100], Loss: 1.0525\n",
      "Train Epoch: [28/100], Loss: 1.0508\n",
      "Train Epoch: [29/100], Loss: 1.0570\n",
      "Train Epoch: [30/100], Loss: 1.0567\n",
      "Train Epoch: [31/100], Loss: 1.0527\n",
      "Train Epoch: [32/100], Loss: 1.0516\n",
      "Train Epoch: [33/100], Loss: 1.0570\n",
      "Train Epoch: [34/100], Loss: 1.0606\n",
      "Train Epoch: [35/100], Loss: 1.0592\n",
      "Train Epoch: [36/100], Loss: 1.0588\n",
      "Train Epoch: [37/100], Loss: 1.0562\n",
      "Train Epoch: [38/100], Loss: 1.0546\n",
      "Train Epoch: [39/100], Loss: 1.0564\n",
      "Train Epoch: [40/100], Loss: 1.0502\n",
      "Train Epoch: [41/100], Loss: 1.0518\n",
      "Train Epoch: [42/100], Loss: 1.0526\n",
      "Train Epoch: [43/100], Loss: 1.0516\n",
      "Train Epoch: [44/100], Loss: 1.0525\n",
      "Train Epoch: [45/100], Loss: 1.0543\n",
      "Train Epoch: [46/100], Loss: 1.0481\n",
      "Train Epoch: [47/100], Loss: 1.0504\n",
      "Train Epoch: [48/100], Loss: 1.0531\n",
      "Train Epoch: [49/100], Loss: 1.0514\n",
      "Train Epoch: [50/100], Loss: 1.0508\n",
      "Train Epoch: [51/100], Loss: 1.0495\n",
      "Train Epoch: [52/100], Loss: 1.0499\n",
      "Train Epoch: [53/100], Loss: 1.0531\n",
      "Train Epoch: [54/100], Loss: 1.0543\n",
      "Train Epoch: [55/100], Loss: 1.0550\n",
      "Train Epoch: [56/100], Loss: 1.0577\n",
      "Train Epoch: [57/100], Loss: 1.0552\n",
      "Train Epoch: [58/100], Loss: 1.0543\n",
      "Train Epoch: [59/100], Loss: 1.0518\n",
      "Train Epoch: [60/100], Loss: 1.0510\n",
      "Train Epoch: [61/100], Loss: 1.0464\n",
      "Train Epoch: [62/100], Loss: 1.0473\n",
      "Train Epoch: [63/100], Loss: 1.0481\n",
      "Train Epoch: [64/100], Loss: 1.0512\n",
      "Train Epoch: [65/100], Loss: 1.0506\n",
      "Train Epoch: [66/100], Loss: 1.0523\n",
      "Train Epoch: [67/100], Loss: 1.0489\n",
      "Train Epoch: [68/100], Loss: 1.0503\n",
      "Train Epoch: [69/100], Loss: 1.0482\n",
      "Train Epoch: [70/100], Loss: 1.0488\n",
      "Train Epoch: [71/100], Loss: 1.0481\n",
      "Train Epoch: [72/100], Loss: 1.0482\n",
      "Train Epoch: [73/100], Loss: 1.0466\n",
      "Train Epoch: [74/100], Loss: 1.0480\n",
      "Train Epoch: [75/100], Loss: 1.0495\n",
      "Train Epoch: [76/100], Loss: 1.0523\n",
      "Train Epoch: [77/100], Loss: 1.0567\n",
      "Train Epoch: [78/100], Loss: 1.0536\n",
      "Train Epoch: [79/100], Loss: 1.0517\n",
      "Train Epoch: [80/100], Loss: 1.0526\n",
      "Train Epoch: [81/100], Loss: 1.0516\n",
      "Train Epoch: [82/100], Loss: 1.0504\n",
      "Train Epoch: [83/100], Loss: 1.0470\n",
      "Train Epoch: [84/100], Loss: 1.0500\n",
      "Train Epoch: [85/100], Loss: 1.0503\n",
      "Train Epoch: [86/100], Loss: 1.0510\n",
      "Train Epoch: [87/100], Loss: 1.0497\n",
      "Train Epoch: [88/100], Loss: 1.0528\n",
      "Train Epoch: [89/100], Loss: 1.0462\n",
      "Train Epoch: [90/100], Loss: 1.0480\n",
      "Train Epoch: [91/100], Loss: 1.0469\n",
      "Train Epoch: [92/100], Loss: 1.0492\n",
      "Train Epoch: [93/100], Loss: 1.0456\n",
      "Train Epoch: [94/100], Loss: 1.0490\n",
      "Train Epoch: [95/100], Loss: 1.0488\n",
      "Train Epoch: [96/100], Loss: 1.0477\n",
      "Train Epoch: [97/100], Loss: 1.0461\n",
      "Train Epoch: [98/100], Loss: 1.0486\n",
      "Train Epoch: [99/100], Loss: 1.0476\n",
      "Train Epoch: [100/100], Loss: 1.0456\n",
      "Fold 5 - Test Accuracy: 50.39%\n"
     ]
    }
   ],
   "source": [
    "# Using cross-validation\n",
    "num_features = node_features.shape[1]\n",
    "hidden_dim = 32\n",
    "num_labels = 3\n",
    "num_heads = 4\n",
    "dropout = 0.6\n",
    "lr = 0.005\n",
    "weight_decay = 5e-4\n",
    "epochs = 100\n",
    "\n",
    "# Convert labels tensor to numpy for StratifiedKFold\n",
    "labels_np = labels.numpy()\n",
    "# Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "splits = list(skf.split(np.arange(len(labels_np) // 4), labels_np[::4])) #should be 3 instead of 4?\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(splits):\n",
    "    print(f'Fold {fold + 1}/{len(splits)}')\n",
    "    \n",
    "    train_mask = np.repeat(train_idx, 4)\n",
    "    test_mask = np.repeat(test_idx, 4)\n",
    "    \n",
    "    train_dataset = JetGraphDataset(node_features[train_mask], edge_index, labels[train_mask])\n",
    "    test_dataset = JetGraphDataset(node_features[test_mask], edge_index, labels[test_mask])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = GATModel(num_features=num_features, hidden_dim=hidden_dim, num_labels=num_labels, num_heads=num_heads, dropout=dropout)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    train(model, optimizer, loss_fn, train_loader, epochs=epochs)\n",
    "    test_accuracy = test(model, test_loader)\n",
    "    \n",
    "    # train(model, optimizer, loss_fn, train_loader, epochs=epochs)\n",
    "    # test_accuracy = test(model, test_loader)\n",
    "    \n",
    "    print(f'Fold {fold + 1} - Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a08a2-ec7a-4353-af76-4aea404d1b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edae05a-df17-4715-85df-dff71a9f411d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe747c6-74fa-4539-b57d-8f03632f3ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
