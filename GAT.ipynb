{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1884e161-5d34-4043-a6d7-956ec632cbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "# from coffea.analysis_tools import PackedSelection\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcba49de-c5fc-4232-be2d-917131427ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/con_np/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/coffea/nanoevents/schemas/nanoaod.py:201: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/Users/con_np/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/coffea/nanoevents/schemas/nanoaod.py:201: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file_path = 'https://xrootd-local.unl.edu:1094//store/user/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19980_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext3-v1_00000_0000.root'\n",
    "tree_name = 'Events'\n",
    "# events = NanoEventsFactory.from_root({file_path: tree_name}, schemaclass=NanoAODSchema).events()\n",
    "events = NanoEventsFactory.from_root(file_path, treepath=tree_name, entry_stop=400000, schemaclass=NanoAODSchema).events() #not full events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb359e3-3f91-4f2a-b8ab-026a546a5b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#code from jetassignment_training\n",
    "selected_electrons = events.Electron[(events.Electron.pt > 30) & (np.abs(events.Electron.eta)<2.1) & \n",
    "                                        (events.Electron.cutBased==4) & (events.Electron.sip3d < 4)]\n",
    "selected_muons = events.Muon[(events.Muon.pt > 30) & (np.abs(events.Muon.eta)<2.1) & (events.Muon.tightId) & \n",
    "                                (events.Muon.sip3d < 4) & (events.Muon.pfRelIso04_all < 0.15)]\n",
    "jet_filter = (events.Jet.pt > 30) & (np.abs(events.Jet.eta) < 2.4) & (events.Jet.isTightLeptonVeto)\n",
    "selected_jets = events.Jet[jet_filter]\n",
    "selected_genpart = events.GenPart\n",
    "even = (events.event%2==0)\n",
    "    \n",
    "# single lepton requirement\n",
    "event_filters = ((ak.count(selected_electrons.pt, axis=1) + ak.count(selected_muons.pt, axis=1)) == 1)\n",
    "# require at least 4 jets\n",
    "event_filters = event_filters & (ak.count(selected_jets.pt, axis=1) >= 4)\n",
    "# require at least one jet above B_TAG_THRESHOLD\n",
    "B_TAG_THRESHOLD = 0.5\n",
    "event_filters = event_filters & (ak.sum(selected_jets.btagCSVV2 >= B_TAG_THRESHOLD, axis=1) >= 1)\n",
    "    \n",
    "# apply event filters\n",
    "selected_electrons = selected_electrons[event_filters]\n",
    "selected_muons = selected_muons[event_filters]\n",
    "selected_jets = selected_jets[event_filters]\n",
    "selected_genpart = selected_genpart[event_filters]\n",
    "even = even[event_filters]\n",
    "    \n",
    "### only consider 4j2b (signal) region\n",
    "region_filter = ak.sum(selected_jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1) >= 2 # at least two b-tagged jets\n",
    "selected_jets_region = selected_jets[region_filter][:,:4] # only keep top 4 jets\n",
    "selected_electrons_region = selected_electrons[region_filter]\n",
    "selected_muons_region = selected_muons[region_filter]\n",
    "selected_genpart_region = selected_genpart[region_filter]\n",
    "even = even[region_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d4f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't need even\n",
    "jets, electrons, muons, labels, even = utils.ml.training_filter(selected_jets_region, \n",
    "                                                        selected_electrons_region, \n",
    "                                                        selected_muons_region, \n",
    "                                                        selected_genpart_region,\n",
    "                                                        even)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce70c41",
   "metadata": {},
   "source": [
    "### Pre-processing data for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "618fc4c4-3515-48e9-9558-cda94eff43de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce2d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jet_lepton_dR(jet_p4, lep_p4): #each event has 4 jets\n",
    "    dR_array = np.array([])\n",
    "    for event in range(len(jet_p4)):\n",
    "        dR = np.array([np.sqrt((lep_p4[event].eta - jet_p4[event,i].eta)**2 + (lep_p4[event].phi - jet_p4[event,i].phi)**2) for i in range(4)])\n",
    "        dR_array = np.append(dR_array, dR)\n",
    "    return dR_array\n",
    "\n",
    "def combinedMass(jet_p4, lep_p4):\n",
    "    mass_array = np.array([])\n",
    "    for event in range(len(jet_p4)):\n",
    "        mass = [lep_p4[event].mass + jet_p4[event].mass]\n",
    "        mass_array = np.append(mass_array, mass)\n",
    "    return mass_array\n",
    "\n",
    "def array_to_tensor(array, chunk_size=1000, dtype=torch.float32):\n",
    "    # converting numpy.array into torch.tensor\n",
    "    # chunk iteration because of too many event\n",
    "    chunks_tensor = []\n",
    "    num_rows, num_col = array.shape\n",
    "    for row_start in range(0, num_rows, chunk_size):\n",
    "        row_end = min(row_start+chunk_size, num_rows)\n",
    "        small_array = array[row_start:row_end]\n",
    "        small_tensor = torch.tensor(small_array, dtype=torch.float32)\n",
    "        chunks_tensor.append(small_tensor)\n",
    "    return torch.cat(chunks_tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7459cc9-2eda-4d6b-abc8-8a1661f653ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_p4 = ak.zip({'pt': electrons.pt, 'eta': electrons.eta, 'phi': electrons.phi, 'mass': electrons.mass}, with_name= 'Momentum4D')\n",
    "mu_p4 = ak.zip({'pt': muons.pt, 'eta': muons.eta, 'phi': muons.phi, 'mass': muons.mass}, with_name= 'Momentum4D')\n",
    "lep_p4 = ak.concatenate((el_p4, mu_p4), axis=1)\n",
    "jet_p4 = ak.zip({'pt': jets.pt, 'eta': jets.eta, 'phi': jets.phi, 'mass': jets.mass}, with_name= 'Momentum4D')\n",
    "\n",
    "#node features from jets\n",
    "jet_pt = ak.flatten(jets.pt, axis=1).to_numpy()\n",
    "jet_mass = ak.flatten(jets.mass, axis=1).to_numpy()\n",
    "jet_phi = ak.flatten(jets.phi, axis=1).to_numpy()\n",
    "jet_eta = ak.flatten(jets.eta, axis=1).to_numpy()\n",
    "jet_btag = ak.flatten(jets.btagCSVV2, axis=1).to_numpy()\n",
    "jet_qgl = ak.flatten(jets.qgl, axis=1).to_numpy()\n",
    "# node features from jets+leptons\n",
    "jet_lep_dR = jet_lepton_dR(jet_p4, lep_p4)\n",
    "jet_lep_mass = combinedMass(jet_p4, lep_p4)\n",
    "\n",
    "# creating 2d array. Row is nodes (the total number of jets) with columns are features \n",
    "node_features = np.vstack((jet_pt, \n",
    "                           jet_mass,\n",
    "                           jet_phi, \n",
    "                           jet_eta, \n",
    "                           jet_btag, \n",
    "                           jet_qgl, \n",
    "                           jet_lep_dR, #dR between each jet and lepton (in the same event, 4 jets and 1 lepton)\n",
    "                           jet_lep_mass)).T #combined mass of each jet and lepton (in the same event, 4 jets and 1 lepton)\n",
    "\n",
    "# convert node_features_array to ninde_features_tensor\n",
    "node_features_tensor = array_to_tensor(node_features)\n",
    "# labels_tensor for jet assignment \n",
    "labels = torch.tensor(labels.flatten(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84e198b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating edge_indices for each event\n",
    "def sub_event_edge_indices(num_jets_in_event):\n",
    "    row = np.tile(np.arange(num_jets_in_event), num_jets_in_event)\n",
    "    col = np.repeat(np.arange(num_jets_in_event), num_jets_in_event)\n",
    "    #excluding edge with itself\n",
    "    mask = row != col\n",
    "    row = row[mask]\n",
    "    col = col[mask]\n",
    "\n",
    "    edge_idx = np.stack([row, col], axis=0)\n",
    "    return edge_idx\n",
    "\n",
    "# creating edge_indices for all event\n",
    "def full_edge_indices(num_jets_in_event, num_events):\n",
    "    edge_indices = []\n",
    "    offset = 0\n",
    "    for _ in range(num_events):\n",
    "        edge_index = sub_event_edge_indices(num_jets_in_event)\n",
    "        edge_index += offset\n",
    "        edge_indices.append(edge_index)\n",
    "        offset += num_jets_in_event\n",
    "    \n",
    "    concat_edge_indices = np.concatenate(edge_indices, axis=1)\n",
    "    return array_to_tensor(concat_edge_indices.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6484a7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1933"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.num(jets, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3535e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events = ak.num(jets, axis=0)\n",
    "num_jets_in_event = 4\n",
    "\n",
    "# edge_indices = []\n",
    "# offset = 0\n",
    "# for _ in range(num_events):\n",
    "#     edge_index = sub_event_edge_indices(num_jets_in_event)\n",
    "#     edge_index += offset\n",
    "#     edge_indices.append(edge_index)\n",
    "#     offset += num_jets_in_event\n",
    "\n",
    "# concat_edge_indices = np.concatenate(edge_indices, axis=1)\n",
    "# test = (array_to_tensor(concat_edge_indices.T)).T\n",
    "\n",
    "full_edge_indices = full_edge_indices(num_jets_in_event, num_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66579501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7732, 8]), torch.Size([2, 23196]), torch.Size([7732]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_tensor.shape, full_edge_indices.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e639c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JetGraphDataset(Dataset):\n",
    "    def __init__(self, node_features, edge_idx, labels):\n",
    "        self.node_features = node_features\n",
    "        self.edge_idx = edge_idx\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.node_features[idx], self.edge_idx, self.labels[idx]\n",
    "\n",
    "\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_labels, num_heads, dropout):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, hidden_dim, heads=num_heads, dropout=dropout)\n",
    "        self.conv2 = GATConv(hidden_dim*num_heads, hidden_dim, heads=num_heads, dropout=dropout)\n",
    "        self.conv3 = GATConv(hidden_dim*num_heads, num_labels, heads=1, concat=True, dropout=dropout)\n",
    "        self.dropout = torch.nn.Dropout(p=0.6)\n",
    "        # self.final_layer = nn.Linear(hidden_dim*num_heads, num_labels)\n",
    "    def forward(self, x, edge_index):\n",
    "        # x, edge_index = data.x, data.edge_index\n",
    "        # First GAT layer\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        # Second GAT layer (optional)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        # last layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return F.softmax(x, dim=1) #F.log_softmax(x, dim=1)\n",
    "\n",
    "# def train(model, optimizer, loss_fn, node_features, labels, epochs=100):\n",
    "def train(model, optimizer, loss_fn, train_loader, device, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (node_features, edge_index, labels) in enumerate(train_loader):\n",
    "            node_features, labels = node_features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(node_features, edge_index.to(device))\n",
    "            loss = loss_fn(output, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Train Epoch: [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "        \n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for node_features, edge_index, labels in test_loader:\n",
    "            node_features, labels = node_features.to(device), labels.to(device)\n",
    "            output = model(node_features, edge_index.to(device))\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a38f9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6b7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e620161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(node_features_tensor, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "train_dataset = JetGraphDataset(X_train, full_edge_indices, y_train)\n",
    "test_dataset = JetGraphDataset(X_test, full_edge_indices, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc01ac0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d2dd16e",
   "metadata": {},
   "source": [
    "### Using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "522f751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_features = node_features_tensor.shape[1]\n",
    "hidden_dim = 32\n",
    "num_labels = 4\n",
    "num_heads = 4\n",
    "dropout = 0.6\n",
    "lr = 0.005\n",
    "weight_decay = 5e-4\n",
    "epochs = 50\n",
    "\n",
    "#K-folds\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23a62d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, test_idx) in enumerate(skf.split(node_features_tensor, labels)):\n",
    "    print(f'Fold {fold+1}/{k_folds}')\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    train_loader = DataLoader(JetGraphDataset(node_features_tensor, full_edge_indices, labels), batch_size=32, sampler=train_sampler)\n",
    "    test_loader = DataLoader(JetGraphDataset(node_features_tensor, full_edge_indices, labels), batch_size=32, sampler=test_sampler)\n",
    "\n",
    "    model = GATModel(num_features=num_features, hidden_dim=hidden_dim, num_labels=num_labels, num_heads=num_heads, dropout=dropout).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    #train and test the model\n",
    "    train(model, optimizer, loss_fn, train_loader, device, epochs=epochs) #kernel crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "train_loader = DataLoader(JetGraphDataset(node_features_tensor, full_edge_indices, labels), batch_size=32, sampler=train_sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d981db9e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
