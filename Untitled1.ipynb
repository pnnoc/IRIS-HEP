{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import uproot as ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_filter_multiple_jets(jets, electrons, muons, genparts, mets):\n",
    "    '''\n",
    "    Filters events down to training set and calculates jet-level labels\n",
    "    \n",
    "    Args:\n",
    "        jets: selected jets after region filter (and selecting leading four for each event)\n",
    "        electrons: selected electrons after region filter\n",
    "        muons: selected muons after region filter\n",
    "        genparts: selected genpart after region filter\n",
    "        even: whether the event is even-numbered (used to separate training events)\n",
    "    \n",
    "    Returns:\n",
    "        jets: selected jets after training filter\n",
    "        electrons: selected electrons after training filter\n",
    "        muons: selected muons after training filter\n",
    "        labels: labels of jets within an event (24=W, 6=top_hadron, -6=top_lepton)\n",
    "        even: whether the event is even-numbered\n",
    "    '''\n",
    "    #### filter genPart to valid matching candidates ####\n",
    "\n",
    "    # get rid of particles without parents\n",
    "    genpart_parent = genparts.distinctParent\n",
    "    genpart_filter = np.invert(ak.is_none(genpart_parent, axis=1))\n",
    "    genparts = genparts[genpart_filter]\n",
    "    genpart_parent = genparts.distinctParent\n",
    "\n",
    "    # ensure that parents are top quark or W\n",
    "    genpart_filter2 = ((np.abs(genpart_parent.pdgId)==6) | (np.abs(genpart_parent.pdgId)==24))\n",
    "    genparts = genparts[genpart_filter2]\n",
    "\n",
    "    # ensure particle itself is a quark\n",
    "    genpart_filter3 = ((np.abs(genparts.pdgId)<7) & (np.abs(genparts.pdgId)>0))\n",
    "    genparts = genparts[genpart_filter3]\n",
    "\n",
    "    # get rid of duplicates\n",
    "    genpart_filter4 = genparts.hasFlags(\"isLastCopy\")\n",
    "    genparts = genparts[genpart_filter4]\n",
    "            \n",
    "        \n",
    "    #### get jet-level labels and filter events to training set\n",
    "        \n",
    "    # match jets to nearest valid genPart candidate\n",
    "    nearest_genpart = jets.nearest(genparts, threshold=0.4)\n",
    "    nearest_parent = nearest_genpart.distinctParent # parent of matched particle\n",
    "    parent_pdgid = nearest_parent.pdgId # pdgId of parent particle\n",
    "    grandchild_pdgid = nearest_parent.distinctChildren.distinctChildren.pdgId # pdgId of particle's parent's grandchildren\n",
    "\n",
    "    grandchildren_flat = np.abs(ak.flatten(grandchild_pdgid,axis=-1)) # flatten innermost axis for convenience\n",
    "\n",
    "    # if particle has a cousin that is a lepton\n",
    "    has_lepton_cousin = (ak.sum(((grandchildren_flat%2==0) & (grandchildren_flat>10) & (grandchildren_flat<19)),\n",
    "                                axis=-1)>0)\n",
    "    # if particle has a cousin that is a neutrino\n",
    "    has_neutrino_cousin = (ak.sum(((grandchildren_flat%2==1) & (grandchildren_flat>10) & (grandchildren_flat<19)),\n",
    "                                  axis=-1)>0)\n",
    "\n",
    "    # if a particle has a lepton cousin and a neutrino cousin\n",
    "    has_both_cousins = ak.fill_none((has_lepton_cousin & has_neutrino_cousin), False) #not using .to_numpy bc inregular array size (different event level, multiple jets)\n",
    "\n",
    "    # get labels from parent pdgId (fill none with 100 to filter out events with those jets)\n",
    "    labels = np.abs(ak.fill_none(parent_pdgid,100)) #not using .to_numpy bc inregular array size (different event level, multiple jets)\n",
    "\n",
    "    # changing the labels while still preserve awkward array jets. To bypass inplace assignment error of numpy_array vs awkward_array\n",
    "    new_labels = ak.Array([])\n",
    "    for idx in range(len(labels)):\n",
    "        (labels[idx].to_numpy())[has_both_cousins[idx].to_numpy()]=-6\n",
    "        new_labels = ak.concatenate([new_labels, ak.Array([labels[idx]])], axis=0)\n",
    "    labels = new_labels\n",
    "    \n",
    "    #mask for event validation (atleast 4 jets with -6, 6, 24, 24, 100, 100,...)\n",
    "    mask = ak.Array([])\n",
    "    for idx in range(len(labels)):\n",
    "        event_valid_bool = (ak.sum(labels[idx]==-6)==1) & (ak.sum(labels[idx]==6)==1) & (ak.sum(labels[idx]==24)==2)\n",
    "        mask = ak.concatenate([mask, ak.Array([event_valid_bool])], axis=0)\n",
    "            \n",
    "    # filter events\n",
    "    jets = jets[mask]\n",
    "    electrons = electrons[mask]\n",
    "    muons = muons[mask]\n",
    "    labels = labels[mask]\n",
    "    mets = mets[mask]\n",
    "    \n",
    "    return jets, electrons, muons, mets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'https://xrootd-local.unl.edu:1094//store/user/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19980_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext3-v1_10000_0000.root'\n",
    "tree_name = 'Events'\n",
    "events = NanoEventsFactory.from_root(file_path, treepath=tree_name, schemaclass=NanoAODSchema).events()\n",
    "\n",
    "print(max(ak.num(events.Jet, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba71e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPANet Event Filtering\n",
    "selected_electrons = events.Electron[(events.Electron.pt > 30) & (np.abs(events.Electron.eta)<2.1) & \n",
    "                                        (events.Electron.cutBased==4) & (events.Electron.sip3d < 4)]\n",
    "selected_muons = events.Muon[(events.Muon.pt > 30) & (np.abs(events.Muon.eta)<2.1) & (events.Muon.tightId) & \n",
    "                                (events.Muon.sip3d < 4) & (events.Muon.pfRelIso04_all < 0.15)]\n",
    "jet_filter = (events.Jet.pt > 30) & (np.abs(events.Jet.eta) < 2.4) & (events.Jet.isTightLeptonVeto)\n",
    "selected_jets = events.Jet[jet_filter]\n",
    "selected_genpart = events.GenPart\n",
    "selected_MET = events.MET # Part of SPANet features\n",
    "\n",
    "# single lepton requirement\n",
    "event_filters = ((ak.count(selected_electrons.pt, axis=1) + ak.count(selected_muons.pt, axis=1)) == 1)\n",
    "# require at least 4 jets\n",
    "event_filters = event_filters & (ak.count(selected_jets.pt, axis=1) >= 4)\n",
    "# require at least one jet above B_TAG_THRESHOLD\n",
    "B_TAG_THRESHOLD = 0.5\n",
    "event_filters = event_filters & (ak.sum(selected_jets.btagCSVV2 >= B_TAG_THRESHOLD, axis=1) >= 1)\n",
    "\n",
    "# apply event filters\n",
    "selected_electrons = selected_electrons[event_filters]\n",
    "selected_muons = selected_muons[event_filters]\n",
    "selected_jets = selected_jets[event_filters]\n",
    "selected_genpart = selected_genpart[event_filters]\n",
    "selected_MET = selected_MET[event_filters]\n",
    "\n",
    "### only consider 4j2b (signal) region\n",
    "region_filter = ak.sum(selected_jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1) >= 2 # at least two b-tagged jets\n",
    "selected_jets_region = selected_jets[region_filter] # all jet\n",
    "selected_electrons_region = selected_electrons[region_filter]\n",
    "selected_muons_region = selected_muons[region_filter]\n",
    "selected_genpart_region = selected_genpart[region_filter]\n",
    "selected_MET_region = selected_MET[region_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eed4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting labels for valid event\n",
    "jets, electrons, muons, mets, labels = training_filter_multiple_jets(selected_jets_region, selected_electrons_region, selected_muons_region, selected_genpart_region, selected_MET_region)\n",
    "print(max(ak.num(jets, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jets\n",
    "jets_btag = jets.btagCSVV2 #awkward array (not padded yet)\n",
    "jets_mass = jets.mass\n",
    "jets_pt = jets.pt\n",
    "jets_eta = jets.eta\n",
    "jets_sin_phi = np.sin(jets.phi)\n",
    "jets_cos_phi = np.cos(jets.phi)\n",
    "\n",
    "#Met\n",
    "mets_sumEt = mets.sumEt #awkward array (no padded needed)\n",
    "mets_sin_phi = np.sin(mets.phi)\n",
    "mets_cos_phi = np.cos(mets.phi)\n",
    "\n",
    "num_events = ak.num(jets, axis=0)\n",
    "\n",
    "#initializing (for memory allocation)\n",
    "leptons_btag = np.zeros(num_events)\n",
    "leptons_mass = np.zeros(num_events)\n",
    "leptons_pt = np.zeros(num_events)\n",
    "leptons_eta = np.zeros(num_events)\n",
    "leptons_sin_phi = np.zeros(num_events)\n",
    "leptons_cos_phi = np.zeros(num_events)\n",
    "\n",
    "# creating lepton mask (either one electron or one muon)\n",
    "has_electron = ak.num(electrons, axis=1) > 0\n",
    "has_muon = ak.num(muons, axis=1) > 0\n",
    "\n",
    "#filling electrons features from events\n",
    "leptons_mass[has_electron] = electrons.mass[has_electron][:, 0]\n",
    "leptons_pt[has_electron] = electrons.pt[has_electron][:, 0]\n",
    "leptons_eta[has_electron] = electrons.eta[has_electron][:, 0]\n",
    "leptons_sin_phi[has_electron] = np.sin(electrons.phi[has_electron][:, 0])\n",
    "leptons_cos_phi[has_electron] = np.cos(electrons.phi[has_electron][:, 0])\n",
    "#fillinig  muons features from events\n",
    "leptons_mass[has_muon] = muons.mass[has_muon][:, 0]\n",
    "leptons_pt[has_muon] = muons.pt[has_muon][:, 0]\n",
    "leptons_eta[has_muon] = muons.eta[has_muon][:, 0]\n",
    "leptons_sin_phi[has_muon] = np.sin(muons.phi[has_muon][:, 0])\n",
    "leptons_cos_phi[has_muon] = np.cos(muons.phi[has_muon][:, 0])\n",
    "\n",
    "# Combining momenta (leptons + jets)\n",
    "# max_num_jets = ak.max(ak.num(jets, axis=1))\n",
    "max_num_jets = 13\n",
    "\n",
    "momenta_btag = np.zeros((num_events, max_num_jets + 1)) #initializing 2d array. num_events*(max_num_jets+1 lepton) (padded)\n",
    "momenta_mass = np.zeros((num_events, max_num_jets + 1))\n",
    "momenta_pt = np.zeros((num_events, max_num_jets + 1))\n",
    "momenta_eta = np.zeros((num_events, max_num_jets + 1))\n",
    "momenta_sin_phi = np.zeros((num_events, max_num_jets + 1))\n",
    "momenta_cos_phi = np.zeros((num_events, max_num_jets + 1))\n",
    "\n",
    "#the 0th argument from lepton information\n",
    "momenta_btag[:, 0] = leptons_btag #no btag for electron. Thus, all zero.\n",
    "momenta_mass[:, 0] = leptons_mass\n",
    "momenta_pt[:, 0] = leptons_pt\n",
    "momenta_eta[:, 0] = leptons_eta\n",
    "momenta_sin_phi[:, 0] = leptons_sin_phi\n",
    "momenta_cos_phi[:, 0] = leptons_cos_phi\n",
    "\n",
    "#filling jets into momenta\n",
    "for idx in range(max_num_jets): #going through jets level\n",
    "    mask = ak.num(jets, axis=1) > idx #filtering events that has num_jets > idx\n",
    "    momenta_btag[mask, idx + 1] = jets_btag[mask][:, idx]\n",
    "    momenta_mass[mask, idx + 1] = jets_mass[mask][:, idx]\n",
    "    momenta_pt[mask, idx + 1] = jets_pt[mask][:, idx]\n",
    "    momenta_eta[mask, idx + 1] = jets_eta[mask][:, idx]\n",
    "    momenta_sin_phi[mask, idx + 1] = jets_sin_phi[mask][:, idx]\n",
    "    momenta_cos_phi[mask, idx + 1] = jets_cos_phi[mask][:, idx]\n",
    "\n",
    "momenta_MASK = momenta_mass != 0 #this should valid (since mass would never be zero -> jets/leptons exist)\n",
    "\n",
    "#convert met to numpy\n",
    "mets_sumEt = mets_sumEt.to_numpy()\n",
    "mets_sin_phi = mets_sin_phi.to_numpy()\n",
    "mets_cos_phi = mets_cos_phi.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAGET indices ###\n",
    "#ht\n",
    "b_had_indices = np.zeros(num_events, dtype=int)\n",
    "q1_indices = np.zeros(num_events, dtype=int)\n",
    "q2_indices = np.zeros(num_events, dtype=int)\n",
    "#lt\n",
    "b_lep_indices = np.zeros(num_events, dtype=int)\n",
    "l_indices = np.zeros(num_events, dtype=int)\n",
    "\n",
    "b_lep_indices[:] = ak.argmax(labels == -6, axis=1) + 1 #avoiding for-loop since there is exact one -6 and one 6\n",
    "b_had_indices[:] = ak.argmax(labels == 6, axis=1) + 1\n",
    "  \n",
    "# Find indices for 24\n",
    "for idx, event in enumerate(labels):\n",
    "    q_indices = ak.where(event == 24)[0]\n",
    "    q1_indices[idx] = q_indices[0] + 1\n",
    "    q2_indices[idx] = q_indices[1] + 1\n",
    "    \n",
    "### Preparing data for h5 file ###\n",
    "#INPUTS\n",
    "##Momenta\n",
    "momenta_data = {\n",
    "    'MASK': momenta_MASK, # capital MASK\n",
    "    'mass': momenta_mass,\n",
    "    'pt': momenta_pt,\n",
    "    'eta': momenta_eta,\n",
    "    'cos_phi': momenta_cos_phi,\n",
    "    'sin_phi': momenta_sin_phi,\n",
    "    'btag': momenta_btag,\n",
    "}\n",
    "##Met\n",
    "met_data = {\n",
    "    'sumet': mets_sumEt,\n",
    "    'cos_phi': mets_cos_phi,\n",
    "    'sin_phi': mets_sin_phi,\n",
    "}\n",
    "\n",
    "\n",
    "#TARGETS\n",
    "ht_target = {\n",
    "    'b': b_had_indices,\n",
    "    'q1': q1_indices,\n",
    "    'q2': q2_indices,\n",
    "}\n",
    "\n",
    "lt_target = {\n",
    "    'b': b_lep_indices,\n",
    "    'l': l_indices,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating h5 file\n",
    "with h5py.File('training_SPANet_structure_ext3-v1_00000_0005.h5', 'w') as h5file:\n",
    "    #INPUTS\n",
    "    input_group = h5file.create_group('INPUTS')\n",
    "    momenta_subgroup = input_group.create_group('Momenta')\n",
    "    met_subgroup = input_group.create_group('Met')\n",
    "\n",
    "    for key, value in momenta_data.items():\n",
    "        momenta_subgroup.create_dataset(key, data=value)\n",
    "    for key, value in met_data.items():\n",
    "        met_subgroup.create_dataset(key, data=value)\n",
    "\n",
    "    #EVENT\n",
    "    event_group = h5file.create_group('TARGETS')\n",
    "    ht_subgroup = event_group.create_group('ht')\n",
    "    lt_subgroup = event_group.create_group('lt')\n",
    "    \n",
    "    for key, value in ht_target.items():\n",
    "        ht_subgroup.create_dataset(key, data=value)\n",
    "\n",
    "    for key, value in lt_target.items():\n",
    "        lt_subgroup.create_dataset(key, data=value)\n",
    "\n",
    "    #PERMUTATION\n",
    "    perm_group = h5file.create_group('PERMUTATION')\n",
    "\n",
    "    #REGRESSION\n",
    "    regression_group = h5file.create_group('REGRESSION')\n",
    "\n",
    "    #CLASSIFICATION\n",
    "    classification_group = h5file.create_group('CLASSIFICATION')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
