{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: dealing with jets symmetries (quark)\n",
    "\n",
    "Special Loss function: dealing with particle symmetries (top and anti-top)\n",
    "\n",
    "Tensor Attention: endoding the symmetries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: unordered jets\n",
    "Outpu: one head per particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "import awkward as ak\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['INPUTS', 'TARGETS']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['MASK', 'btag', 'eta', 'mass', 'phi', 'pt']>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing reading h5 file (full_hadronic_ttbar from SPANet)\n",
    "filename = '/Users/con_np/Desktop/IRIS-HEP/SPANet/data/full_hadronic_ttbar/example.h5'\n",
    "# with h5py.File(filename, 'r') as f:\n",
    "#     print('Key:', f.keys())\n",
    "\n",
    "f = h5py.File(filename, 'r')\n",
    "print(f.keys())\n",
    "f['INPUTS'].keys(), f['TARGETS'].keys()\n",
    "f['INPUTS']['Source'].keys() # <KeysViewHDF5 ['MASK', 'btag', 'eta', 'mass', 'phi', 'pt']>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MASK', 'btag', 'eta', 'mass', 'phi', 'pt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f['INPUTS']['Source'].keys())\n",
    "# f['INPUTS']['Source']['pt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.2251196, 6.8190174, 6.1047554, 6.731269 , 5.0331483, 2.8288946,\n",
       "        2.6951485, 3.0092976, 0.       , 0.       ], dtype=float32),\n",
       " array([50.61789 , 45.034477, 36.778576, 34.147022, 32.926132, 32.87439 ,\n",
       "        26.713516, 24.644855,  0.      ,  0.      ], dtype=float32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['INPUTS']['Source']['mass'][2], f['INPUTS']['Source']['pt'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 (b,q1,q2): 0 -1 1\n",
      "t2 (b,q1,q2): 4 6 3\n"
     ]
    }
   ],
   "source": [
    "event = 2\n",
    "print('t1 (b,q1,q2):', f['TARGETS']['t1']['b'][event], f['TARGETS']['t1']['q1'][event], f['TARGETS']['t1']['q2'][event]) \n",
    "print('t2 (b,q1,q2):', f['TARGETS']['t2']['b'][event], f['TARGETS']['t2']['q1'][event], f['TARGETS']['t2']['q2'][event])\n",
    "\n",
    "# In the event 2, 0th jet = b_t1, 4th jet = b_t2, 6th jet = q1_t2, 3rd jet = q2_t2, 1st jet = q2_t1, -1 (missing target) = q1_t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a target value of i in TARGETS/event_particle/jet_product would correspond to the ith jet in the JET input array for that event. A target value of j in TARGETS/event_particle/leptonic_product would correspond to the jth lepton in the Leptons input array for that event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================\n",
    "| Structure for data/full_hadronic_ttbar/example.h5 \n",
    "============================================================\n",
    "\n",
    "|-INPUTS                        \n",
    "|---Source                      \n",
    "|-----MASK                       :: bool     : (10000, 10)\n",
    "|-----btag                       :: float32  : (10000, 10)\n",
    "|-----eta                        :: float32  : (10000, 10)\n",
    "|-----mass                       :: float32  : (10000, 10)\n",
    "|-----phi                        :: float32  : (10000, 10)\n",
    "|-----pt                         :: float32  : (10000, 10)\n",
    "|-TARGETS                       \n",
    "|---t1                          \n",
    "|-----b                          :: int64    : (10000,)\n",
    "|-----q1                         :: int64    : (10000,)\n",
    "|-----q2                         :: int64    : (10000,)\n",
    "|---t2                          \n",
    "|-----b                          :: int64    : (10000,)\n",
    "|-----q1                         :: int64    : (10000,)\n",
    "|-----q2                         :: int64    : (10000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 1, 3, 4, 5, 6, -1]\n"
     ]
    }
   ],
   "source": [
    "un = []\n",
    "for label in f['TARGETS']['t1']['b'][:]:\n",
    "    if label not in un:\n",
    "        un.append(label)\n",
    "\n",
    "print(un)\n",
    "# what does each label represent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 (b,q1,q2): 0 -1 1\n",
      "t2 (b,q1,q2): 4 6 3\n"
     ]
    }
   ],
   "source": [
    "event = 2\n",
    "print('t1 (b,q1,q2):', f['TARGETS']['t1']['b'][event], f['TARGETS']['t1']['q1'][event], f['TARGETS']['t1']['q2'][event]) \n",
    "print('t2 (b,q1,q2):', f['TARGETS']['t2']['b'][event], f['TARGETS']['t2']['q1'][event], f['TARGETS']['t2']['q2'][event]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.2251196, 6.8190174, 6.1047554, 6.731269 , 5.0331483, 2.8288946,\n",
       "       2.6951485, 3.0092976, 0.       , 0.       ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['INPUTS']['Source']['mass'][event]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting from coffea to h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/con_np/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/coffea/nanoevents/schemas/nanoaod.py:201: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/Users/con_np/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/coffea/nanoevents/schemas/nanoaod.py:201: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#writing h5 from coffea schema\n",
    "file_path = 'https://xrootd-local.unl.edu:1094//store/user/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19980_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext3-v1_00000_0000.root'\n",
    "tree_name = 'Events'\n",
    "# events = NanoEventsFactory.from_root({file_path: tree_name}, schemaclass=NanoAODSchema).events()\n",
    "events = NanoEventsFactory.from_root(file_path, treepath=tree_name, schemaclass=NanoAODSchema).events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from jetassignment_training\n",
    "# events filtering\n",
    "selected_electrons = events.Electron[(events.Electron.pt > 30) & (np.abs(events.Electron.eta)<2.1) & \n",
    "                                        (events.Electron.cutBased==4) & (events.Electron.sip3d < 4)]\n",
    "selected_muons = events.Muon[(events.Muon.pt > 30) & (np.abs(events.Muon.eta)<2.1) & (events.Muon.tightId) & \n",
    "                                (events.Muon.sip3d < 4) & (events.Muon.pfRelIso04_all < 0.15)]\n",
    "jet_filter = (events.Jet.pt > 30) & (np.abs(events.Jet.eta) < 2.4) & (events.Jet.isTightLeptonVeto)\n",
    "selected_jets = events.Jet[jet_filter]\n",
    "selected_genpart = events.GenPart\n",
    "even = (events.event%2==0)\n",
    "    \n",
    "# single lepton requirement\n",
    "event_filters = ((ak.count(selected_electrons.pt, axis=1) + ak.count(selected_muons.pt, axis=1)) == 1)\n",
    "# require at least 4 jets\n",
    "event_filters = event_filters & (ak.count(selected_jets.pt, axis=1) >= 4)\n",
    "# require at least one jet above B_TAG_THRESHOLD\n",
    "B_TAG_THRESHOLD = 0.5\n",
    "event_filters = event_filters & (ak.sum(selected_jets.btagCSVV2 >= B_TAG_THRESHOLD, axis=1) >= 1)\n",
    "    \n",
    "# apply event filters\n",
    "selected_electrons = selected_electrons[event_filters]\n",
    "selected_muons = selected_muons[event_filters]\n",
    "selected_jets = selected_jets[event_filters]\n",
    "selected_genpart = selected_genpart[event_filters]\n",
    "even = even[event_filters]\n",
    "    \n",
    "### only consider 4j2b (signal) region\n",
    "region_filter = ak.sum(selected_jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1) >= 2 # at least two b-tagged jets\n",
    "selected_jets_region = selected_jets[region_filter][:,:10] # only keep top 10 jets\n",
    "selected_electrons_region = selected_electrons[region_filter]\n",
    "selected_muons_region = selected_muons[region_filter]\n",
    "selected_genpart_region = selected_genpart[region_filter]\n",
    "even = even[region_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(array, max_jets=10, pad_value=0):\n",
    "    padded_array = ak.pad_none(array, max_jets, axis=1)\n",
    "    padded_array_filled = ak.fill_none(padded_array, pad_value, axis=1)\n",
    "    return padded_array_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating padded features for each event\n",
    "Jets_pt_padded = pad_array(selected_jets_region.pt)\n",
    "Jets_mass_padded = pad_array(selected_jets_region.mass)\n",
    "Jets_eta_padded = pad_array(selected_jets_region.eta)\n",
    "Jets_phi_padded = pad_array(selected_jets_region.phi)\n",
    "Jets_btag_padded = pad_array(selected_jets_region.btagCSVV2)\n",
    "Jets_qgl_padded = pad_array(selected_jets_region.qgl)\n",
    "\n",
    "#lepton features (only electrons left)\n",
    "lep_pt_padded = pad_array(selected_electrons_region.pt)\n",
    "lep_mass_padded = pad_array(selected_electrons_region.mass)\n",
    "lep_eta_padded = pad_array(selected_electrons_region.eta)\n",
    "lep_phi_padded = pad_array(selected_electrons_region.phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating MASK for each event\n",
    "pad_check = ak.pad_none(selected_jets_region.pt, 10, axis=1)\n",
    "Jets_mask_padded = np.invert(ak.is_none(pad_check, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing sequential data for h5 file\n",
    "jet_data = {\n",
    "    'mask': Jets_mask_padded,\n",
    "    'mass': Jets_mass_padded,\n",
    "    'pt': Jets_pt_padded,\n",
    "    'eta': Jets_eta_padded,\n",
    "    'phi': Jets_phi_padded,\n",
    "    'btag': Jets_btag_padded,\n",
    "    'qgl': Jets_qgl_padded,\n",
    "}\n",
    "\n",
    "lep_data = {\n",
    "    'mass':lep_mass_padded,\n",
    "    'pt':lep_pt_padded,\n",
    "    'eta':lep_eta_padded,\n",
    "    'phi':lep_phi_padded\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need some kind of labels\n",
    "# STILL NEED TO WORK ON IT\n",
    "t1 = {\n",
    "    'b': ,\n",
    "    'q1': ,\n",
    "    'q2':\n",
    "    }\n",
    "t2 = {\n",
    "    'b': ,\n",
    "    'mu': ,\n",
    "    'nu':\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating h5 file\n",
    "with h5py.File('test2.h5', 'w') as h5file:\n",
    "    #INPUTS\n",
    "    input_group = h5file.create_group('INPUTS')\n",
    "    seq_subgroup = input_group.create_group('SEQUENTIAL')\n",
    "    global_subgroup = input_group.create_group('GLOBAL')\n",
    "\n",
    "    jet_2subgroup = seq_subgroup.create_group('Jet')\n",
    "    lept_2subgroup = seq_subgroup.create_group('Lepton')\n",
    "\n",
    "    for key, value in jet_data.items():\n",
    "        jet_2subgroup.create_dataset(key, data=ak.to_numpy(value))\n",
    "\n",
    "    for key, value in lep_data.items():\n",
    "        lept_2subgroup.create_dataset(key, data=ak.to_numpy(value))\n",
    "\n",
    "    #EVENT\n",
    "    event_group = h5file.create_group('TARGETS')\n",
    "    t1_subgroup = event_group.create_group('t1')\n",
    "    t2_subgroup = event_group.create_group('t2')\n",
    "\n",
    "\n",
    "    #PERMUTATION\n",
    "    perm_group = h5file.create_group('PERMUTATION')\n",
    "\n",
    "    #REGRESSION\n",
    "    regression_group = h5file.create_group('REGRESSION')\n",
    "\n",
    "    #CLASSIFICATION\n",
    "    classification_group = h5file.create_group('CLASSIFICATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading from test.h5 file\n",
    "#testing reading h5 file\n",
    "filename_test = 'test2.h5'\n",
    "f = h5py.File(filename_test, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([141.625  ,  40.53125,  34.375  ,  33.96875,   0.     ,   0.     ,\n",
       "         0.     ,   0.     ,   0.     ,   0.     ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['INPUTS']['SEQUENTIAL']['Jet']['pt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "| Structure for test2.h5 \n",
      "============================================================\n",
      "\n",
      "|-CLASSIFICATION                \n",
      "|-INPUTS                        \n",
      "|---GLOBAL                      \n",
      "|---SEQUENTIAL                  \n",
      "|-----Jet                       \n",
      "|-------btag                     :: float64  : (28616, 10)\n",
      "|-------eta                      :: float64  : (28616, 10)\n",
      "|-------mask                     :: bool     : (28616, 10)\n",
      "|-------mass                     :: float64  : (28616, 10)\n",
      "|-------phi                      :: float64  : (28616, 10)\n",
      "|-------pt                       :: float64  : (28616, 10)\n",
      "|-------qgl                      :: float64  : (28616, 10)\n",
      "|-----Lepton                    \n",
      "|-------eta                      :: float64  : (28616, 10)\n",
      "|-------mass                     :: float64  : (28616, 10)\n",
      "|-------phi                      :: float64  : (28616, 10)\n",
      "|-------pt                       :: float64  : (28616, 10)\n",
      "|-PERMUTATION                   \n",
      "|-REGRESSION                    \n",
      "|-TARGETS                       \n",
      "|---t1                          \n",
      "|---t2                          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python utils/examine_hdf5.py test2.h5 --shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding SPANet Data/Model Construction (based on the demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
