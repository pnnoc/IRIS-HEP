{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: dealing with jets symmetries (quark)\n",
    "\n",
    "Special Loss function: dealing with particle symmetries (top and anti-top)\n",
    "\n",
    "Tensor Attention: endoding the symmetries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: unordered jets\n",
    "Outpu: one head per particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "import awkward as ak\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting from coffea to h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/con_np/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/coffea/nanoevents/schemas/nanoaod.py:201: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/Users/con_np/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/coffea/nanoevents/schemas/nanoaod.py:201: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#writing h5 from coffea schema\n",
    "file_path = 'https://xrootd-local.unl.edu:1094//store/user/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19980_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext3-v1_00000_0000.root'\n",
    "tree_name = 'Events'\n",
    "# events = NanoEventsFactory.from_root({file_path: tree_name}, schemaclass=NanoAODSchema).events()\n",
    "events = NanoEventsFactory.from_root(file_path, treepath=tree_name, schemaclass=NanoAODSchema).events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from jetassignment_training\n",
    "# events filtering\n",
    "selected_electrons = events.Electron[(events.Electron.pt > 30) & (np.abs(events.Electron.eta)<2.1) & \n",
    "                                        (events.Electron.cutBased==4) & (events.Electron.sip3d < 4)]\n",
    "selected_muons = events.Muon[(events.Muon.pt > 30) & (np.abs(events.Muon.eta)<2.1) & (events.Muon.tightId) & \n",
    "                                (events.Muon.sip3d < 4) & (events.Muon.pfRelIso04_all < 0.15)]\n",
    "jet_filter = (events.Jet.pt > 30) & (np.abs(events.Jet.eta) < 2.4) & (events.Jet.isTightLeptonVeto)\n",
    "selected_jets = events.Jet[jet_filter]\n",
    "selected_genpart = events.GenPart\n",
    "even = (events.event%2==0)\n",
    "    \n",
    "# single lepton requirement\n",
    "event_filters = ((ak.count(selected_electrons.pt, axis=1) + ak.count(selected_muons.pt, axis=1)) == 1)\n",
    "# require at least 4 jets\n",
    "event_filters = event_filters & (ak.count(selected_jets.pt, axis=1) >= 4)\n",
    "# require at least one jet above B_TAG_THRESHOLD\n",
    "B_TAG_THRESHOLD = 0.5\n",
    "event_filters = event_filters & (ak.sum(selected_jets.btagCSVV2 >= B_TAG_THRESHOLD, axis=1) >= 1)\n",
    "    \n",
    "# apply event filters\n",
    "selected_electrons = selected_electrons[event_filters]\n",
    "selected_muons = selected_muons[event_filters]\n",
    "selected_jets = selected_jets[event_filters]\n",
    "selected_genpart = selected_genpart[event_filters]\n",
    "even = even[event_filters]\n",
    "    \n",
    "### only consider 4j2b (signal) region\n",
    "region_filter = ak.sum(selected_jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1) >= 2 # at least two b-tagged jets\n",
    "selected_jets_region = selected_jets[region_filter][:,:10] # only keep top 10 jets\n",
    "selected_electrons_region = selected_electrons[region_filter]\n",
    "selected_muons_region = selected_muons[region_filter]\n",
    "selected_genpart_region = selected_genpart[region_filter]\n",
    "even = even[region_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(array, max_jets=10, pad_value=0):\n",
    "    padded_array = ak.pad_none(array, max_jets, axis=1)\n",
    "    padded_array_filled = ak.fill_none(padded_array, pad_value, axis=1)\n",
    "    return padded_array_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating padded features for each event\n",
    "Jets_pt_padded = pad_array(selected_jets_region.pt)\n",
    "Jets_mass_padded = pad_array(selected_jets_region.mass)\n",
    "Jets_eta_padded = pad_array(selected_jets_region.eta)\n",
    "Jets_phi_padded = pad_array(selected_jets_region.phi)\n",
    "Jets_btag_padded = pad_array(selected_jets_region.btagCSVV2)\n",
    "Jets_qgl_padded = pad_array(selected_jets_region.qgl)\n",
    "\n",
    "#lepton features (only electrons left)\n",
    "lep_pt_padded = pad_array(selected_electrons_region.pt)\n",
    "lep_mass_padded = pad_array(selected_electrons_region.mass)\n",
    "lep_eta_padded = pad_array(selected_electrons_region.eta)\n",
    "lep_phi_padded = pad_array(selected_electrons_region.phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating MASK for each event\n",
    "pad_check = ak.pad_none(selected_jets_region.pt, 10, axis=1)\n",
    "Jets_mask_padded = np.invert(ak.is_none(pad_check, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing sequential data for h5 file\n",
    "jet_data = {\n",
    "    'mask': Jets_mask_padded,\n",
    "    'mass': Jets_mass_padded,\n",
    "    'pt': Jets_pt_padded,\n",
    "    'eta': Jets_eta_padded,\n",
    "    'phi': Jets_phi_padded,\n",
    "    'btag': Jets_btag_padded,\n",
    "    'qgl': Jets_qgl_padded,\n",
    "}\n",
    "\n",
    "lep_data = {\n",
    "    'mass':lep_mass_padded,\n",
    "    'pt':lep_pt_padded,\n",
    "    'eta':lep_eta_padded,\n",
    "    'phi':lep_phi_padded\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need some kind of labels\n",
    "# STILL NEED TO WORK ON IT\n",
    "t1 = {\n",
    "    'b': ,\n",
    "    'q1': ,\n",
    "    'q2':\n",
    "    }\n",
    "t2 = {\n",
    "    'b': ,\n",
    "    'mu': ,\n",
    "    'nu':\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating h5 file\n",
    "with h5py.File('test2.h5', 'w') as h5file:\n",
    "    #INPUTS\n",
    "    input_group = h5file.create_group('INPUTS')\n",
    "    seq_subgroup = input_group.create_group('SEQUENTIAL')\n",
    "    global_subgroup = input_group.create_group('GLOBAL')\n",
    "\n",
    "    jet_2subgroup = seq_subgroup.create_group('Jet')\n",
    "    lept_2subgroup = seq_subgroup.create_group('Lepton')\n",
    "\n",
    "    for key, value in jet_data.items():\n",
    "        jet_2subgroup.create_dataset(key, data=ak.to_numpy(value))\n",
    "\n",
    "    for key, value in lep_data.items():\n",
    "        lept_2subgroup.create_dataset(key, data=ak.to_numpy(value))\n",
    "\n",
    "    #EVENT\n",
    "    event_group = h5file.create_group('TARGETS')\n",
    "    t1_subgroup = event_group.create_group('t1')\n",
    "    t2_subgroup = event_group.create_group('t2')\n",
    "\n",
    "\n",
    "    #PERMUTATION\n",
    "    perm_group = h5file.create_group('PERMUTATION')\n",
    "\n",
    "    #REGRESSION\n",
    "    regression_group = h5file.create_group('REGRESSION')\n",
    "\n",
    "    #CLASSIFICATION\n",
    "    classification_group = h5file.create_group('CLASSIFICATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading from test.h5 file\n",
    "#testing reading h5 file\n",
    "filename_test = 'test2.h5'\n",
    "f = h5py.File(filename_test, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([141.625  ,  40.53125,  34.375  ,  33.96875,   0.     ,   0.     ,\n",
       "         0.     ,   0.     ,   0.     ,   0.     ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['INPUTS']['SEQUENTIAL']['Jet']['pt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "| Structure for test2.h5 \n",
      "============================================================\n",
      "\n",
      "|-CLASSIFICATION                \n",
      "|-INPUTS                        \n",
      "|---GLOBAL                      \n",
      "|---SEQUENTIAL                  \n",
      "|-----Jet                       \n",
      "|-------btag                     :: float64  : (28616, 10)\n",
      "|-------eta                      :: float64  : (28616, 10)\n",
      "|-------mask                     :: bool     : (28616, 10)\n",
      "|-------mass                     :: float64  : (28616, 10)\n",
      "|-------phi                      :: float64  : (28616, 10)\n",
      "|-------pt                       :: float64  : (28616, 10)\n",
      "|-------qgl                      :: float64  : (28616, 10)\n",
      "|-----Lepton                    \n",
      "|-------eta                      :: float64  : (28616, 10)\n",
      "|-------mass                     :: float64  : (28616, 10)\n",
      "|-------phi                      :: float64  : (28616, 10)\n",
      "|-------pt                       :: float64  : (28616, 10)\n",
      "|-PERMUTATION                   \n",
      "|-REGRESSION                    \n",
      "|-TARGETS                       \n",
      "|---t1                          \n",
      "|---t2                          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python utils/examine_hdf5.py test2.h5 --shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding SPANet Data/Model Construction (based on the demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_target_label(file_read):\n",
    "    lt_dict = {'l': [], 'b': []}\n",
    "    ht_dict = {'q1': [], 'q2': [], 'b': []}\n",
    "    \n",
    "    for key, value in lt_dict.items():\n",
    "        for label in file_read['TARGETS']['lt'][key][:]:\n",
    "            if label not in lt_dict[key]:\n",
    "                lt_dict[key].append(label)\n",
    "                \n",
    "    for key, value in ht_dict.items():\n",
    "        for label in file_read['TARGETS']['ht'][key][:]:\n",
    "            if label not in ht_dict[key]:\n",
    "                ht_dict[key].append(label)\n",
    "    \n",
    "    return lt_dict, ht_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cloud h5 files reading test\n",
    "train_filepath_cloud = '/eos/user/n/nmuangko/semi_leptonnic_ttbar/training_mass_variation.h5'\n",
    "test_filepath_cloud = '/eos/user/n/nmuangko/semi_leptonnic_ttbar/testing_mass_variation.h5'\n",
    "# filepath_test = 'testing_mass_variation.h5' #path from SWAN\n",
    "# filepath_train = 'training_mass_variation.h5'\n",
    "train_file = h5py.File(train_filepath_cloud,'r')\n",
    "test_file = h5py.File(test_filepath_cloud,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KeysViewHDF5 ['INPUTS', 'REGRESSIONS', 'TARGETS']>,\n",
       " <KeysViewHDF5 ['INPUTS', 'REGRESSIONS', 'TARGETS']>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file.keys(), test_file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "| Structure for /eos/user/n/nmuangko/semi_leptonnic_ttbar/testing_mass_variation.h5 \n",
      "============================================================\n",
      "\n",
      "|-INPUTS                        \n",
      "|---Met                         \n",
      "|-----cos_phi                    :: float32  : (1865837,)\n",
      "|-----met                        :: float32  : (1865837,)\n",
      "|-----sin_phi                    :: float32  : (1865837,)\n",
      "|-----sumet                      :: float32  : (1865837,)\n",
      "|---Momenta                     \n",
      "|-----MASK                       :: bool     : (1865837, 16)\n",
      "|-----btag                       :: float32  : (1865837, 16)\n",
      "|-----cos_phi                    :: float32  : (1865837, 16)\n",
      "|-----eta                        :: float32  : (1865837, 16)\n",
      "|-----etag                       :: float32  : (1865837, 16)\n",
      "|-----mass                       :: float32  : (1865837, 16)\n",
      "|-----pt                         :: float32  : (1865837, 16)\n",
      "|-----qtag                       :: float32  : (1865837, 16)\n",
      "|-----rapidity                   :: float32  : (1865837, 16)\n",
      "|-----sin_phi                    :: float32  : (1865837, 16)\n",
      "|-----utag                       :: float32  : (1865837, 16)\n",
      "|-REGRESSIONS                   \n",
      "|---EVENT                       \n",
      "|-----invariant_mass             :: float32  : (1865837,)\n",
      "|-----log_invariant_mass         :: float32  : (1865837,)\n",
      "|-----log_neutrino_eta           :: float32  : (1865837,)\n",
      "|-----log_neutrino_px            :: float32  : (1865837,)\n",
      "|-----log_neutrino_py            :: float32  : (1865837,)\n",
      "|-----log_neutrino_pz            :: float32  : (1865837,)\n",
      "|-----neutrino_eta               :: float32  : (1865837,)\n",
      "|-----neutrino_px                :: float32  : (1865837,)\n",
      "|-----neutrino_py                :: float32  : (1865837,)\n",
      "|-----neutrino_pz                :: float32  : (1865837,)\n",
      "|---ht                          \n",
      "|-----PARTICLE                  \n",
      "|-------invariant_mass           :: float32  : (1865837,)\n",
      "|-------log_invariant_mass       :: float32  : (1865837,)\n",
      "|---lt                          \n",
      "|-----PARTICLE                  \n",
      "|-------invariant_mass           :: float32  : (1865837,)\n",
      "|-------log_invariant_mass       :: float32  : (1865837,)\n",
      "|-TARGETS                       \n",
      "|---ht                          \n",
      "|-----b                          :: int64    : (1865837,)\n",
      "|-----q1                         :: int64    : (1865837,)\n",
      "|-----q2                         :: int64    : (1865837,)\n",
      "|---lt                          \n",
      "|-----b                          :: int64    : (1865837,)\n",
      "|-----l                          :: int64    : (1865837,)\n",
      "\n",
      "============================================================\n",
      "| Structure for /eos/user/n/nmuangko/semi_leptonnic_ttbar/training_mass_variation.h5 \n",
      "============================================================\n",
      "\n",
      "|-INPUTS                        \n",
      "|---Met                         \n",
      "|-----cos_phi                    :: float32  : (12427644,)\n",
      "|-----met                        :: float32  : (12427644,)\n",
      "|-----sin_phi                    :: float32  : (12427644,)\n",
      "|-----sumet                      :: float32  : (12427644,)\n",
      "|---Momenta                     \n",
      "|-----MASK                       :: bool     : (12427644, 16)\n",
      "|-----btag                       :: float32  : (12427644, 16)\n",
      "|-----cos_phi                    :: float32  : (12427644, 16)\n",
      "|-----eta                        :: float32  : (12427644, 16)\n",
      "|-----etag                       :: float32  : (12427644, 16)\n",
      "|-----mass                       :: float32  : (12427644, 16)\n",
      "|-----pt                         :: float32  : (12427644, 16)\n",
      "|-----qtag                       :: float32  : (12427644, 16)\n",
      "|-----rapidity                   :: float32  : (12427644, 16)\n",
      "|-----sin_phi                    :: float32  : (12427644, 16)\n",
      "|-----utag                       :: float32  : (12427644, 16)\n",
      "|-REGRESSIONS                   \n",
      "|---EVENT                       \n",
      "|-----invariant_mass             :: float32  : (12427644,)\n",
      "|-----log_invariant_mass         :: float32  : (12427644,)\n",
      "|-----log_neutrino_eta           :: float32  : (12427644,)\n",
      "|-----log_neutrino_px            :: float32  : (12427644,)\n",
      "|-----log_neutrino_py            :: float32  : (12427644,)\n",
      "|-----log_neutrino_pz            :: float32  : (12427644,)\n",
      "|-----mt                         :: float32  : (12427644,)\n",
      "|-----mx                         :: float32  : (12427644,)\n",
      "|-----neutrino_eta               :: float32  : (12427644,)\n",
      "|-----neutrino_px                :: float32  : (12427644,)\n",
      "|-----neutrino_py                :: float32  : (12427644,)\n",
      "|-----neutrino_pz                :: float32  : (12427644,)\n",
      "|---ht                          \n",
      "|-----PARTICLE                  \n",
      "|-------invariant_mass           :: float32  : (12427644,)\n",
      "|-------log_invariant_mass       :: float32  : (12427644,)\n",
      "|---lt                          \n",
      "|-----PARTICLE                  \n",
      "|-------invariant_mass           :: float32  : (12427644,)\n",
      "|-------log_invariant_mass       :: float32  : (12427644,)\n",
      "|-TARGETS                       \n",
      "|---ht                          \n",
      "|-----b                          :: int64    : (12427644,)\n",
      "|-----q1                         :: int64    : (12427644,)\n",
      "|-----q2                         :: int64    : (12427644,)\n",
      "|---lt                          \n",
      "|-----b                          :: int64    : (12427644,)\n",
      "|-----l                          :: int64    : (12427644,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python utils/examine_hdf5.py /eos/user/n/nmuangko/semi_leptonnic_ttbar/testing_mass_variation.h5 --shape\n",
    "python utils/examine_hdf5.py /eos/user/n/nmuangko/semi_leptonnic_ttbar/training_mass_variation.h5 --shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leptonic top side: l [0]\n",
      "Leptonic top side: b [2, 6, 3, 1, 4, -1, 5, 8, 7, 11, 10, 9, 14, 12]\n",
      "Hadronic top side: q1 [3, 4, 2, 1, -1, 5, 6, 7, 8, 9, 10, 11]\n",
      "Hadronic top side: q2 [-1, 7, 4, 5, 3, 6, 2, 8, 9, 10, 11, 12, 13]\n",
      "Hadronic top side: b [-1, 2, 1, 3, 6, 4, 5, 7, 8, 9, 12, 10, 11, 14]\n"
     ]
    }
   ],
   "source": [
    "lt_dict, ht_dict = check_target_label(f_test)\n",
    "\n",
    "for key, value in lt_dict.items():\n",
    "    print('Leptonic top side:', key, value)\n",
    "for key, value in ht_dict.items():\n",
    "    print('Hadronic top side:', key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reducing testing and training size to avoid kernal crash\n",
    "def copy_group(source_group, target_group, n_events_to_copy):\n",
    "    for key in source_group.keys():\n",
    "        item = source_group[key]\n",
    "        if isinstance(item, h5py.Group):\n",
    "            # Create the group in the target file\n",
    "            print(f\"Creating group {key}\")\n",
    "            new_group = target_group.create_group(key)\n",
    "            # Recursively copy the subgroup\n",
    "            copy_group(item, new_group, n_events_to_copy)\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            print(f\"Copying dataset {key}\")\n",
    "            # Copy the dataset with a subset of data\n",
    "            if item.ndim == 1:\n",
    "                target_group.create_dataset(key, data=item[:n_events_to_copy])\n",
    "            else:\n",
    "                target_group.create_dataset(key, data=item[:n_events_to_copy, :])\n",
    "        else:\n",
    "            print(f\"Skipping unknown item type for {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newfile_path_test_subset = 'testing_mass_variation_subset_v2.h5'\n",
    "newfile_path_train_subset = 'training_mass_variation_subset_v2.h5'\n",
    "\n",
    "ratio = 0.8\n",
    "test_num_events = int(ratio*(1865837))\n",
    "train_num_events = int(ratio*(12427644))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating group INPUTS\n",
      "Creating group Met\n",
      "Copying dataset cos_phi\n",
      "Copying dataset met\n",
      "Copying dataset sin_phi\n",
      "Copying dataset sumet\n",
      "Creating group Momenta\n",
      "Copying dataset MASK\n",
      "Copying dataset btag\n",
      "Copying dataset cos_phi\n",
      "Copying dataset eta\n",
      "Copying dataset etag\n",
      "Copying dataset mass\n",
      "Copying dataset pt\n",
      "Copying dataset qtag\n",
      "Copying dataset rapidity\n",
      "Copying dataset sin_phi\n",
      "Copying dataset utag\n",
      "Creating group REGRESSIONS\n",
      "Creating group EVENT\n",
      "Copying dataset invariant_mass\n",
      "Copying dataset log_invariant_mass\n",
      "Copying dataset log_neutrino_eta\n",
      "Copying dataset log_neutrino_px\n",
      "Copying dataset log_neutrino_py\n",
      "Copying dataset log_neutrino_pz\n",
      "Copying dataset mt\n",
      "Copying dataset mx\n",
      "Copying dataset neutrino_eta\n",
      "Copying dataset neutrino_px\n",
      "Copying dataset neutrino_py\n",
      "Copying dataset neutrino_pz\n",
      "Creating group ht\n",
      "Creating group PARTICLE\n",
      "Copying dataset invariant_mass\n",
      "Copying dataset log_invariant_mass\n",
      "Creating group lt\n",
      "Creating group PARTICLE\n",
      "Copying dataset invariant_mass\n",
      "Copying dataset log_invariant_mass\n",
      "Creating group TARGETS\n",
      "Creating group ht\n",
      "Copying dataset b\n",
      "Copying dataset q1\n",
      "Copying dataset q2\n",
      "Creating group lt\n",
      "Copying dataset b\n",
      "Copying dataset l\n"
     ]
    }
   ],
   "source": [
    "# Open the original HDF5 file\n",
    "with h5py.File(train_filepath_cloud, 'r') as train_file:\n",
    "    # Create a new HDF5 file\n",
    "    with h5py.File(newfile_path_train_subset, 'w') as new_train_file:\n",
    "        # Copy the structure and a subset of data\n",
    "        copy_group(train_file, new_train_file, train_num_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating group INPUTS\n",
      "Creating group Met\n",
      "Copying dataset cos_phi\n",
      "Copying dataset met\n",
      "Copying dataset sin_phi\n",
      "Copying dataset sumet\n",
      "Creating group Momenta\n",
      "Copying dataset MASK\n",
      "Copying dataset btag\n",
      "Copying dataset cos_phi\n",
      "Copying dataset eta\n",
      "Copying dataset etag\n",
      "Copying dataset mass\n",
      "Copying dataset pt\n",
      "Copying dataset qtag\n",
      "Copying dataset rapidity\n",
      "Copying dataset sin_phi\n",
      "Copying dataset utag\n",
      "Creating group REGRESSIONS\n",
      "Creating group EVENT\n",
      "Copying dataset invariant_mass\n",
      "Copying dataset log_invariant_mass\n",
      "Copying dataset log_neutrino_eta\n",
      "Copying dataset log_neutrino_px\n",
      "Copying dataset log_neutrino_py\n",
      "Copying dataset log_neutrino_pz\n",
      "Copying dataset neutrino_eta\n",
      "Copying dataset neutrino_px\n",
      "Copying dataset neutrino_py\n",
      "Copying dataset neutrino_pz\n",
      "Creating group ht\n",
      "Creating group PARTICLE\n",
      "Copying dataset invariant_mass\n",
      "Copying dataset log_invariant_mass\n",
      "Creating group lt\n",
      "Creating group PARTICLE\n",
      "Copying dataset invariant_mass\n",
      "Copying dataset log_invariant_mass\n",
      "Creating group TARGETS\n",
      "Creating group ht\n",
      "Copying dataset b\n",
      "Copying dataset q1\n",
      "Copying dataset q2\n",
      "Creating group lt\n",
      "Copying dataset b\n",
      "Copying dataset l\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(test_filepath_cloud, 'r') as test_file:\n",
    "    # Create a new HDF5 file\n",
    "    with h5py.File(newfile_path_test_subset, 'w') as new_test_file:\n",
    "        # Copy the structure and a subset of data\n",
    "        copy_group(test_file, new_test_file, test_num_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/eos/home-i00/n/nmuangko/semi_leptonnic_ttbar/utils/examine_hdf5.py\", line 22, in <module>\n",
      "    main(arguments.filepath, arguments.shape)\n",
      "  File \"/eos/home-i00/n/nmuangko/semi_leptonnic_ttbar/utils/examine_hdf5.py\", line 8, in main\n",
      "    with h5py.File(filepath, 'r') as file:\n",
      "  File \"/cvmfs/sft.cern.ch/lcg/views/LCG_105a_swan/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "  File \"/cvmfs/sft.cern.ch/lcg/views/LCG_105a_swan/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = 'training_mass_variation_subset_v2.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'python utils/examine_hdf5.py training_mass_variation_subset_v2.h5 --shape\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_491/2355577272.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'python utils/examine_hdf5.py training_mass_variation_subset_v2.h5 --shape\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_swan/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2401\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2403\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_swan/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_swan/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_swan/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_105a_swan/x86_64-el9-gcc13-opt/lib/python3.9/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'python utils/examine_hdf5.py training_mass_variation_subset_v2.h5 --shape\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python utils/examine_hdf5.py training_mass_variation_subset_v2.h5 --shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
