{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "# import json\n",
    "# Hists\n",
    "# import hist\n",
    "# from hist import Hist\n",
    "# NanoEvents\n",
    "from coffea.nanoevents import NanoEventsFactory, BaseSchema, NanoAODSchema\n",
    "# Processors\n",
    "# from coffea import processor\n",
    "from coffea.analysis_tools import PackedSelection\n",
    "\n",
    "# import utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch_geometric.data as geom_data\n",
    "# import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.nn import GATConv\n",
    "# from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBAL CONFIGURATION\n",
    "# input files per process, set to e.g. 10 (smaller number = faster)\n",
    "N_FILES_MAX_PER_SAMPLE = 1\n",
    "\n",
    "# enable Dask\n",
    "USE_DASK = False\n",
    "\n",
    "# enable ServiceX\n",
    "USE_SERVICEX = False\n",
    "\n",
    "### ML-INFERENCE SETTINGS\n",
    "\n",
    "# enable ML inference\n",
    "USE_INFERENCE = False\n",
    "\n",
    "# enable inference using NVIDIA Triton server\n",
    "USE_TRITON = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From nanoaod_inputs.json\n",
    "\n",
    "## ttbar\n",
    "- nominal: {'nevts_total': 276079127, 'files':['path':, 'nevts']}\n",
    "- scaledown: {'nevts_total': 39329663, 'files':['path':, 'nevts']}\n",
    "- scaleup: {'nevts_total': 38424467, 'files':['path':, 'nevts']}\n",
    "- ME_var: {'nevts_total': 19098219, 'files':['path':, 'nevts']}\n",
    "- PS_varr: {'nevts_total': 19337064, 'files':['path':, 'nevts']}\n",
    "\n",
    "## single_top_s_chan\n",
    "- \"nominal\": {\"nevts_total\": 2867199, \"files\": ['path':, 'nevts']}\n",
    "\n",
    "## single_top_t_chan\n",
    "- \"nominal\": {\"nevts_total\": 109305936, \"files\": ['path':, 'nevts']}\n",
    "\n",
    "## single_top_tW\n",
    "- \"nominal\": {\"nevts_total\": 1999400, \"files\":['path':, 'nevts']}\n",
    "\n",
    "## wjets\n",
    "- \"nominal\": {\"nevts_total\": 433719099, \"files\": ['path':, 'nevts']}\n",
    "\n",
    "open('').keys()\n",
    "\n",
    "['tag;6',\n",
    " 'tag;5',\n",
    " 'tag;4',\n",
    " 'tag;3',\n",
    " 'tag;2',\n",
    " 'tag;1',\n",
    " 'Events;1',\n",
    " 'LuminosityBlocks;1',\n",
    " 'Runs;1',\n",
    " 'MetaData;1',\n",
    " 'ParameterSets;1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ttbar', 'single_top_s_chan', 'single_top_t_chan', 'single_top_tW', 'wjets'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking \n",
    "# utils.file_input.construct_fileset(N_FILES_MAX_PER_SAMPLE=1, use_xcache=False, af_name=\"coffea_casa\", input_from_eos=False, xcache_atlas_prefix=None)\n",
    "\n",
    "with open('nanoaod_inputs.json') as f:\n",
    "    file_info = json.load(f)\n",
    "\n",
    "file_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsec_info = {\n",
    "    \"ttbar\": 396.87 + 332.97, # nonallhad + allhad, keep same x-sec for all\n",
    "    \"single_top_s_chan\": 2.0268 + 1.2676,\n",
    "    \"single_top_t_chan\": (36.993 + 22.175)/0.252,  # scale from lepton filter to inclusive\n",
    "    \"single_top_tW\": 37.936 + 37.906,\n",
    "    \"wjets\": 61457 * 0.252,  # e/mu+nu final states\n",
    "    \"data\": None\n",
    "}\n",
    "\n",
    "fileset = {}\n",
    "for process in file_info.keys(): #['ttbar', 'single_top_s_chan', 'single_top_t_chan', 'single_top_tW', 'wjets']\n",
    "    # print('process: ', process)\n",
    "    for variation in file_info[process].keys(): # each channel has variation(s). each variatioin has 'nevts' and 'files'\n",
    "        # print(variation)\n",
    "        file_list = file_info[process][variation]['files'] # each file has 'path' and 'nevts'\n",
    "        file_path = [f['path'] for f in file_list]\n",
    "        nevts_total = sum( f['nevts'] for f in file_list)\n",
    "        # print(nevts_total==file_info[process][variation]['nevts_total']) -> true\n",
    "        metadata = {\"process\": process, \"variation\": variation, \"nevts\": nevts_total, \"xsec\": xsec_info[process]}\n",
    "        fileset.update({f'{process}__{variation}': {'files': file_path, 'metadata': metadata}})\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ttbar__nominal', 'ttbar__scaledown', 'ttbar__scaleup', 'ttbar__ME_var', 'ttbar__PS_var', 'single_top_s_chan__nominal', 'single_top_t_chan__nominal', 'single_top_tW__nominal', 'wjets__nominal'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'process': 'ttbar',\n",
       " 'variation': 'scaledown',\n",
       " 'nevts': 39329663,\n",
       " 'xsec': 729.84}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileset['ttbar__scaledown']['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processes in fileset: ['ttbar__nominal', 'ttbar__scaledown', 'ttbar__scaleup', 'ttbar__ME_var', 'ttbar__PS_var', 'single_top_s_chan__nominal', 'single_top_t_chan__nominal', 'single_top_tW__nominal', 'wjets__nominal']\n",
      "\n",
      "example of information in fileset:\n",
      "{\n",
      "  'files': [https://xrootd-local.unl.edu:1094//store/user/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19980_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext3-v1_00000_0000.root, ...],\n",
      "  'metadata': {'process': 'ttbar', 'variation': 'nominal', 'nevts': 1334428, 'xsec': 729.84}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "fileset = utils.file_input.construct_fileset(\n",
    "    N_FILES_MAX_PER_SAMPLE,\n",
    "    use_xcache=False,\n",
    "    af_name=utils.config[\"benchmarking\"][\"AF_NAME\"], # \"coffea_casa\" # local files on /data for af_name=\"ssl-dev\"\n",
    "    input_from_eos=utils.config[\"benchmarking\"][\"INPUT_FROM_EOS\"], # False\n",
    "    xcache_atlas_prefix=utils.config[\"benchmarking\"][\"XCACHE_ATLAS_PREFIX\"], #None\n",
    ")\n",
    "\n",
    "print(f\"processes in fileset: {list(fileset.keys())}\")\n",
    "print(f\"\\nexample of information in fileset:\\n{{\\n  'files': [{fileset['ttbar__nominal']['files'][0]}, ...],\")\n",
    "print(f\"  'metadata': {fileset['ttbar__nominal']['metadata']}\\n}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coffea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/con_np/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/coffea/nanoevents/schemas/nanoaod.py:201: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx1 => SubJet\n",
      "  warnings.warn(\n",
      "/Users/con_np/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/coffea/nanoevents/schemas/nanoaod.py:201: RuntimeWarning: Missing cross-reference index for FatJet_subJetIdx2 => SubJet\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file_path = 'https://xrootd-local.unl.edu:1094//store/user/AGC/nanoAOD/TT_TuneCUETP8M1_13TeV-powheg-pythia8/cmsopendata2015_ttbar_19980_PU25nsData2015v1_76X_mcRun2_asymptotic_v12_ext3-v1_00000_0000.root'\n",
    "tree_name = 'Events'\n",
    "# events = NanoEventsFactory.from_root({file_path: tree_name}, schemaclass=NanoAODSchema).events()\n",
    "events = NanoEventsFactory.from_root(file_path, treepath=tree_name, schemaclass=NanoAODSchema).events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Muon = events.Muon\n",
    "Electron = events.Electron\n",
    "Jet = events.Jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "muon_mask = ((Muon.pt>30) & (np.abs(Muon.eta)<2.1) & (Muon.tightId) & (Muon.sip3d<4) & (Muon.pfRelIso04_all<0.15))\n",
    "electron_mask = ((Electron.pt>30) & (np.abs(Electron.eta)<2.1) & (Electron.cutBased==4) & (Electron.sip3d<4))\n",
    "jet_mask = ((Jet.pt>30) & (np.abs(Jet.eta)<2.4) & (Jet.isTightLeptonVeto))\n",
    "\n",
    "muons = Muon[muon_mask]\n",
    "electrons = Electron[electron_mask]\n",
    "jets = Jet[jet_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "The read operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m selections\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_6j\u001b[39m\u001b[38;5;124m'\u001b[39m, ak\u001b[38;5;241m.\u001b[39mnum(jets)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# exactly_1b\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m selections\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexactly_1b\u001b[39m\u001b[38;5;124m'\u001b[39m, ak\u001b[38;5;241m.\u001b[39msum(\u001b[43mjets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbtagCSVV2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB_TAG_THRESHOLD\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# atleaast_2b\u001b[39;00m\n\u001b[1;32m     13\u001b[0m selections\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124matleast_2b\u001b[39m\u001b[38;5;124m'\u001b[39m, ak\u001b[38;5;241m.\u001b[39msum(jets\u001b[38;5;241m.\u001b[39mbtagCSVV2 \u001b[38;5;241m>\u001b[39m B_TAG_THRESHOLD, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/awkward/_connect/_numpy.py:391\u001b[0m, in \u001b[0;36m_binary_method.<locals>.func\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _disables_array_ufunc(other):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/awkward/highlevel.py:1411\u001b[0m, in \u001b[0;36mArray.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;124;03mIntercepts attempts to pass this Array to a NumPy\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;124;03m[universal functions](https://docs.scipy.org/doc/numpy/reference/ufuncs.html)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;124;03mSee also #__array_function__.\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_tracers\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ak\u001b[38;5;241m.\u001b[39m_connect\u001b[38;5;241m.\u001b[39m_jax\u001b[38;5;241m.\u001b[39mjax_utils\u001b[38;5;241m.\u001b[39marray_ufunc(\n\u001b[1;32m   1414\u001b[0m         \u001b[38;5;28mself\u001b[39m, ufunc, method, inputs, kwargs\n\u001b[1;32m   1415\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/awkward/_connect/_numpy.py:252\u001b[0m, in \u001b[0;36marray_ufunc\u001b[0;34m(ufunc, method, inputs, kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    243\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno overloads for custom types: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    244\u001b[0m                 ufunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;241m+\u001b[39m ak\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39mexception_suffix(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_and_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgetfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbehavior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_records\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ak\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39mwrap(out[\u001b[38;5;241m0\u001b[39m], behavior)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/awkward/_util.py:1172\u001b[0m, in \u001b[0;36mbroadcast_and_apply\u001b[0;34m(inputs, getfunction, behavior, allow_records, pass_depth, pass_user, user, left_broadcast, right_broadcast, numpy_to_regular, regular_to_jagged)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m     isscalar \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1172\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbroadcast_pack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misscalar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(broadcast_unpack(x, isscalar) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m out)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/awkward/_util.py:925\u001b[0m, in \u001b[0;36mbroadcast_and_apply.<locals>.apply\u001b[0;34m(inputs, depth, user)\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    923\u001b[0m         nextinputs\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m--> 925\u001b[0m outcontent \u001b[38;5;241m=\u001b[39m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnextinputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outcontent, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m    928\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/awkward/_util.py:1028\u001b[0m, in \u001b[0;36mbroadcast_and_apply.<locals>.apply\u001b[0;34m(inputs, depth, user)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1026\u001b[0m         nextinputs\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m-> 1028\u001b[0m outcontent \u001b[38;5;241m=\u001b[39m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnextinputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(offsets, ak\u001b[38;5;241m.\u001b[39mlayout\u001b[38;5;241m.\u001b[39mIndex32):\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m   1032\u001b[0m         ak\u001b[38;5;241m.\u001b[39mlayout\u001b[38;5;241m.\u001b[39mListOffsetArray32(offsets, x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m outcontent\n\u001b[1;32m   1033\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/awkward/_util.py:782\u001b[0m, in \u001b[0;36mbroadcast_and_apply.<locals>.apply\u001b[0;34m(inputs, depth, user)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m             nextinputs\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m--> 782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnextinputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, uniontypes) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs):\n\u001b[1;32m    785\u001b[0m     tagslist \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/awkward/_util.py:750\u001b[0m, in \u001b[0;36mbroadcast_and_apply.<locals>.apply\u001b[0;34m(inputs, depth, user)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, virtualtypes):\n\u001b[0;32m--> 750\u001b[0m         nextinputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m)\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    752\u001b[0m         nextinputs\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/awkward/operations/convert.py:4774\u001b[0m, in \u001b[0;36m_form_to_layout\u001b[0;34m(form, container, partnum, key_format, length, lazy_cache, lazy_cache_key)\u001b[0m\n\u001b[1;32m   4768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _form_to_layout_class[\u001b[38;5;28mtype\u001b[39m(form), form\u001b[38;5;241m.\u001b[39moffsets](\n\u001b[1;32m   4769\u001b[0m         offsets, content, identities, parameters\n\u001b[1;32m   4770\u001b[0m     )\n\u001b[1;32m   4772\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(form, ak\u001b[38;5;241m.\u001b[39mforms\u001b[38;5;241m.\u001b[39mNumpyForm):\n\u001b[1;32m   4773\u001b[0m     raw_array \u001b[38;5;241m=\u001b[39m _asbuf(\n\u001b[0;32m-> 4774\u001b[0m         \u001b[43mcontainer\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mform_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattribute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartnum\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4775\u001b[0m     )\n\u001b[1;32m   4777\u001b[0m     dtype_inner_shape \u001b[38;5;241m=\u001b[39m form\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m   4778\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_inner_shape\u001b[38;5;241m.\u001b[39msubdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/coffea/nanoevents/mapping/base.py:90\u001b[0m, in \u001b[0;36mBaseSourceMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_access_log\u001b[38;5;241m.\u001b[39mappend(handle_name)\n\u001b[1;32m     87\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_column_handle(\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_source(uuid, treepath), handle_name\n\u001b[1;32m     89\u001b[0m     )\n\u001b[0;32m---> 90\u001b[0m     stack\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     92\u001b[0m     tname \u001b[38;5;241m=\u001b[39m node[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/coffea/nanoevents/mapping/uproot.py:149\u001b[0m, in \u001b[0;36mUprootSourceMapping.extract_column\u001b[0;34m(self, columnhandle, start, stop)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, columnhandle, start, stop):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# make sure uproot is single-core since our calling context might not be\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcolumnhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mentry_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mentry_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muproot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrivialExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muproot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrivialExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/behaviors/TBranch.py:2208\u001b[0m, in \u001b[0;36mTBranch.array\u001b[0;34m(self, interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, array_cache, library)\u001b[0m\n\u001b[1;32m   2202\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[1;32m   2203\u001b[0m                 basket_num,\n\u001b[1;32m   2204\u001b[0m                 range_or_basket,\n\u001b[1;32m   2205\u001b[0m             ) \u001b[38;5;129;01min\u001b[39;00m branch\u001b[38;5;241m.\u001b[39mentries_to_ranges_or_baskets(entry_start, entry_stop):\n\u001b[1;32m   2206\u001b[0m                 ranges_or_baskets\u001b[38;5;241m.\u001b[39mappend((branch, basket_num, range_or_basket))\n\u001b[0;32m-> 2208\u001b[0m \u001b[43m_ranges_or_baskets_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mranges_or_baskets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbranchid_interpretation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentry_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentry_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2221\u001b[0m _fix_asgrouped(\n\u001b[1;32m   2222\u001b[0m     arrays, expression_context, branchid_interpretation, library, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2223\u001b[0m )\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m array_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/behaviors/TBranch.py:3493\u001b[0m, in \u001b[0;36m_ranges_or_baskets_to_arrays\u001b[0;34m(hasbranches, ranges_or_baskets, branchid_interpretation, entry_start, entry_stop, decompression_executor, interpretation_executor, library, arrays, update_ranges_or_baskets)\u001b[0m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   3492\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 3493\u001b[0m     \u001b[43muproot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayed_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3496\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(obj)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/source/futures.py:36\u001b[0m, in \u001b[0;36mdelayed_raise\u001b[0;34m(exception_class, exception_value, traceback)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelayed_raise\u001b[39m(exception_class, exception_value, traceback):\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Raise an exception from a background thread on the main thread.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_value\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/behaviors/TBranch.py:3414\u001b[0m, in \u001b[0;36m_ranges_or_baskets_to_arrays.<locals>.chunk_to_basket\u001b[0;34m(chunk, branch, basket_num)\u001b[0m\n\u001b[1;32m   3412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3413\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mcursor\u001b[38;5;241m.\u001b[39mCursor(chunk\u001b[38;5;241m.\u001b[39mstart)\n\u001b[0;32m-> 3414\u001b[0m     basket \u001b[38;5;241m=\u001b[39m \u001b[43muproot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTBasket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel_TBasket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbasket_num\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasket_num\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhasbranches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhasbranches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbranch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3422\u001b[0m     original_index \u001b[38;5;241m=\u001b[39m range_original_index[(chunk\u001b[38;5;241m.\u001b[39mstart, chunk\u001b[38;5;241m.\u001b[39mstop)]\n\u001b[1;32m   3423\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_ranges_or_baskets:\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/model.py:837\u001b[0m, in \u001b[0;36mModel.read\u001b[0;34m(cls, chunk, cursor, context, file, selffile, parent, concrete)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreading\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_before_read_members(\n\u001b[1;32m    834\u001b[0m         chunk\u001b[38;5;241m=\u001b[39mchunk, cursor\u001b[38;5;241m=\u001b[39mcursor, context\u001b[38;5;241m=\u001b[39mcontext, file\u001b[38;5;241m=\u001b[39mfile\n\u001b[1;32m    835\u001b[0m     )\n\u001b[0;32m--> 837\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_members\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_after_read_members(\n\u001b[1;32m    840\u001b[0m         chunk\u001b[38;5;241m=\u001b[39mchunk, cursor\u001b[38;5;241m=\u001b[39mcursor, context\u001b[38;5;241m=\u001b[39mcontext, file\u001b[38;5;241m=\u001b[39mfile\n\u001b[1;32m    841\u001b[0m     )\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_numbytes(chunk, cursor, context)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/models/TBasket.py:223\u001b[0m, in \u001b[0;36mModel_TBasket.read_members\u001b[0;34m(self, chunk, cursor, context, file)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent, uproot\u001b[38;5;241m.\u001b[39mbehaviors\u001b[38;5;241m.\u001b[39mTBranch\u001b[38;5;241m.\u001b[39mTBranch)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_basket_num \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasket_num\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    216\u001b[0m (\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_members[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfNbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_version,\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_members[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfObjlen\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_members[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfDatime\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_members[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfKeylen\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_members[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfCycle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m--> 223\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_tbasket_format1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# skip the class name, name, and title\u001b[39;00m\n\u001b[1;32m    226\u001b[0m cursor\u001b[38;5;241m.\u001b[39mmove_to(\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_members[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfKeylen\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m _tbasket_format2\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    228\u001b[0m )\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/source/cursor.py:197\u001b[0m, in \u001b[0;36mCursor.fields\u001b[0;34m(self, chunk, format, context, move)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m move:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m=\u001b[39m stop\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39munpack(\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/source/chunk.py:419\u001b[0m, in \u001b[0;36mChunk.get\u001b[0;34m(self, start, stop, cursor, context)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    start (int): Seek position of the first byte to include.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03malready.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (start, stop) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     local_start \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start\n\u001b[1;32m    421\u001b[0m     local_stop \u001b[38;5;241m=\u001b[39m stop \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/source/chunk.py:356\u001b[0m, in \u001b[0;36mChunk.wait\u001b[0;34m(self, insist)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    insist (bool or int): If True, raise an OSError if ``raw_data`` does\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m:ref:`uproot.source.chunk.Chunk.future` completes).\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_data \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m insist \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m         requirement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/source/futures.py:116\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     \u001b[43mdelayed_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_excinfo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/source/futures.py:36\u001b[0m, in \u001b[0;36mdelayed_raise\u001b[0;34m(exception_class, exception_value, traceback)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelayed_raise\u001b[39m(exception_class, exception_value, traceback):\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Raise an exception from a background thread on the main thread.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_value\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/site-packages/uproot/source/http.py:304\u001b[0m, in \u001b[0;36mHTTPResource.multifuture.<locals>.task\u001b[0;34m(resource)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtask\u001b[39m(resource):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    307\u001b[0m             connection[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/micromamba/envs/r3k_bdttools/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out"
     ]
    }
   ],
   "source": [
    "B_TAG_THRESHOLD = 0.5\n",
    "\n",
    "selections = PackedSelection(dtype='uint64')\n",
    "# exactly_1l\n",
    "selections.add('exactly_1l', (ak.num(electrons)+ak.num(muons))==1) #111711\n",
    "# atleast_4j\n",
    "selections.add('atleast_4j', ak.num(jets)>=4)\n",
    "# max_6j\n",
    "selections.add('max_6j', ak.num(jets)<=6)\n",
    "# exactly_1b\n",
    "selections.add('exactly_1b', ak.sum(jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1)==1)\n",
    "# atleaast_2b\n",
    "selections.add('atleast_2b', ak.sum(jets.btagCSVV2 > B_TAG_THRESHOLD, axis=1)>=2)\n",
    "#combined for each regions\n",
    "selections.add('4j1b', selections.all('atleast_4j','exactly_1l','exactly_1b'))\n",
    "selections.add('4j2b', selections.all('atleast_4j','exactly_1l','atleast_2b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exactly_1l', 'atleast_4j', 'max_6j', 'exactly_1b', 'atleast_2b', '4j1b', '4j2b']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(selections.names)\n",
    "selections.all('4j2b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4j2b region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_selection = selections.all('4j2b','max_6j')\n",
    "jets = jets[region_selection]\n",
    "electrons = electrons[region_selection]\n",
    "muons = muons[region_selection]\n",
    "genpar = GenPar[region_selection]\n",
    "even = (events.event%2==0)\n",
    "even = even[region_selection]\n",
    "#region_weights = np.ones(len(region_jets)) * xsec_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnodes construction:\\n    row would be node graph (muons, electrons, jet)? or should it be the number of permutation\\n    columns would be properties: pt, mass, btag, qgl (maybe eta and phi as well)\\n\\nedge construction:\\n    features: deltaR, combined mass, combine mass\\n\\nProbably have to create torch.Tensor that match the size of input for node features\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#constructing input matrix for GNN\n",
    "'''\n",
    "nodes construction:\n",
    "    row would be node graph (muons, electrons, jet)? or should it be the number of permutation\n",
    "    columns would be properties: pt, mass, btag, qgl (maybe eta and phi as well)\n",
    "\n",
    "edge construction:\n",
    "    features: deltaR, combined mass, combine mass\n",
    "\n",
    "Probably have to create torch.Tensor that match the size of input for node features\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_p4 = ak.zip({'pt': electrons.pt, 'eta': electrons.eta, 'phi': electrons.phi, 'mass': electrons.mass}, with_name= 'Momentum4D')\n",
    "mu_p4 = ak.zip({'pt': muons.pt, 'eta': muons.eta, 'phi': muons.phi, 'mass': muons.mass}, with_name= 'Momentum4D')\n",
    "lep_p4 = ak.concatenate((el_p4, mu_p4), axis=1)\n",
    "jet_p4 = ak.zip({'pt': jets.pt, 'eta': jets.eta, 'phi': jets.phi, 'mass': jets.mass}, with_name= 'Momentum4D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_tensor(array, chunk_size=1000, dtype=torch.float32):\n",
    "    # converting numpy.array into torch.tensor\n",
    "    # chunk iteration because of too many event\n",
    "    chunks_tensor = []\n",
    "    num_rows, num_col = array.shape\n",
    "    for row_start in range(0, num_rows, chunk_size):\n",
    "        row_end = min(row_start+chunk_size, num_rows)\n",
    "        small_array = array[row_start:row_end]\n",
    "        small_tensor = torch.tensor(small_array, dtype=torch.float32)\n",
    "        chunks_tensor.append(small_tensor)\n",
    "    return torch.cat(chunks_tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lep_phi = ak.flatten(lep_p4.phi, axis=1).to_numpy()\n",
    "# lep_eta = ak.flatten(lep_p4.eta, axis=1).to_numpy()\n",
    "# lep_pt = ak.flatten(lep_p4.pt, axis=1).to_numpy()\n",
    "# lep_mass = ak.flatten(lep_p4.mass, axis=1).to_numpy()\n",
    "# lep_features = np.vstack((lep_pt, lep_mass, lep_phi, lep_eta)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_pt = ak.flatten(jets.pt, axis=1).to_numpy()\n",
    "jet_mass = ak.flatten(jets.mass, axis=1).to_numpy()\n",
    "jet_phi = ak.flatten(jets.phi, axis=1).to_numpy()\n",
    "jet_eta = ak.flatten(jets.eta, axis=1).to_numpy()\n",
    "jet_btag = ak.flatten(jets.btagCSVV2, axis=1).to_numpy()\n",
    "jet_qgl = ak.flatten(jets.qgl, axis=1).to_numpy()\n",
    "\n",
    "jet_features = np.vstack((jet_pt, jet_mass, jet_phi, jet_eta, jet_btag, jet_qgl)).T\n",
    "# column pt: 0\n",
    "# column mass: 1\n",
    "# column phi: 2\n",
    "# column eta: 3\n",
    "# column btag: 4\n",
    "# column qcl: 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = array_to_tensor(jet_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GAT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adjacency_matrix(eta, phi, threshold=0.4):\n",
    "    num_particles = len(eta)\n",
    "    adjacency_matrix = np.zeros((num_particles, num_particles))\n",
    "    for i in range(num_particles):\n",
    "        for j in range(i + 1, num_particles):\n",
    "            delta_eta = eta[i] - eta[j]\n",
    "            delta_phi = np.abs(phi[i] - phi[j])\n",
    "            if delta_phi > np.pi:\n",
    "                delta_phi = 2 * np.pi - delta_phi\n",
    "            distance = np.sqrt(delta_eta**2 + delta_phi**2)\n",
    "            if distance < threshold:\n",
    "                adjacency_matrix[i, j] = 1\n",
    "                adjacency_matrix[j, i] = 1\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_adjacency_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adj_30sams \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_adjacency_matrix\u001b[49m(eta\u001b[38;5;241m=\u001b[39mnode_features[:\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m3\u001b[39m], phi\u001b[38;5;241m=\u001b[39mnode_features[:\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_adjacency_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "adj_30sams = create_adjacency_matrix(eta=node_features[:30,3], phi=node_features[:30,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph for each event\n",
    "graphs = []\n",
    "for event_idx in range(len(jet_features)):\n",
    "    features = torch.tensor(jet_features[event_idx], dtype=torch.float)\n",
    "    eta = jet_eta[event_idx]\n",
    "    phi = jet_phi[event_idx]\n",
    "    adjacency_matrix = create_adjacency_matrix(eta, phi)\n",
    "    edge_index = torch.tensor(np.array(np.nonzero(adjacency_matrix)), dtype=torch.long)\n",
    "    graph = Data(x=features, edge_index=edge_index)\n",
    "    graphs.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels): #output_channels would be the number of class labels\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, 8, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(8 * 8, out_channels, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1) #output would be the vector of classes (highest score is the prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we have labels for each node (0: background, 1: signal)\n",
    "# Here we create random labels as a placeholder\n",
    "# In practice, you should replace this with your actual labels\n",
    "labels = [torch.randint(0, 2, (g.num_nodes(),), dtype=torch.long) for g in graphs]\n",
    "\n",
    "# Create DataLoader\n",
    "loader = DataLoader([Data(x=g.x, edge_index=g.edge_index, y=labels[i]) for i, g in enumerate(graphs)], batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = GAT(in_channels=6, out_channels=2).to(device)\n",
    "model = GAT(in_channels=6, out_channels=4) #output dim would be 4?\n",
    "lss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4) #defining optimizer\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    lss = []\n",
    "    val_lss = []\n",
    "    for data in loader:\n",
    "        # data = data.to(device)\n",
    "        optimizer.zero_grad() #clear gradients for each iteration (don't want acculmulated )\n",
    "        out = model(data.x)\n",
    "        loss = lss_fn(out, data.y) # lss_fn(output[data.train_mask], data.y[data.train_mask])\n",
    "        val_loss = lss_fn(out[data.val_mask], data.y[data.val_mask])\n",
    "        loss.backward() #derive gradients\n",
    "        optimizer.step() #update parameters based on gradients\n",
    "        lss.append(loss)\n",
    "        val_lss.append(val_loss)\n",
    "    return lss, val_lss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    acc = []\n",
    "    for data in loader:\n",
    "        out = model(data) #data.x\n",
    "        pred = out.argmax(dim=1) #choising highest class probability\n",
    "        test_correct = pred[data.test_mask]==data.y[data.test_mask] #need syntax modification\n",
    "        test_acc = int(test_correct.sum()) / int(data.test_mask.sum()) #need syntax modification\n",
    "        acc.append(test_acc)\n",
    "    return acc\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):  # Number of epochs\n",
    "    # train()\n",
    "    lss, val_lss = train()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'gat_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import knn_graph\n",
    "\n",
    "class DynamicEdgeGAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, heads=4):\n",
    "        super(DynamicEdgeGAT, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self,output_dim = output_dim\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, out_dim, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        edge_index = knn_graph(x, k=5)  # Create k-NN graph with k=5\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 16 hidden units, 5 classes, and 4 attention heads\n",
    "# model = DynamicEdgeGAT(in_channels=x.size(1), hidden_channels=16, out_channels=5, heads=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['area',\n",
       " 'btagCSVV2',\n",
       " 'btagDeepB',\n",
       " 'btagDeepCvB',\n",
       " 'btagDeepCvL',\n",
       " 'btagDeepFlavB',\n",
       " 'btagDeepFlavCvB',\n",
       " 'btagDeepFlavCvL',\n",
       " 'btagDeepFlavQG',\n",
       " 'chEmEF',\n",
       " 'chFPV0EF',\n",
       " 'chHEF',\n",
       " 'eta',\n",
       " 'mass',\n",
       " 'muEF',\n",
       " 'muonSubtrFactor',\n",
       " 'neEmEF',\n",
       " 'neHEF',\n",
       " 'phi',\n",
       " 'pt',\n",
       " 'puIdDisc',\n",
       " 'qgl',\n",
       " 'rawFactor',\n",
       " 'bRegCorr',\n",
       " 'bRegRes',\n",
       " 'cRegCorr',\n",
       " 'cRegRes',\n",
       " 'electronIdx1',\n",
       " 'electronIdx2',\n",
       " 'jetId',\n",
       " 'muonIdx1',\n",
       " 'muonIdx2',\n",
       " 'nElectrons',\n",
       " 'nMuons',\n",
       " 'puId',\n",
       " 'nConstituents',\n",
       " 'genJetIdx',\n",
       " 'hadronFlavour',\n",
       " 'partonFlavour',\n",
       " 'cleanmask',\n",
       " 'electronIdx1G',\n",
       " 'electronIdx2G',\n",
       " 'genJetIdxG',\n",
       " 'muonIdx1G',\n",
       " 'muonIdx2G',\n",
       " 'muonIdxG',\n",
       " 'electronIdxG']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jets.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(ak.flatten(jets.jetId, axis=1).to_numpy().T, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels\n",
    "labels = torch.tensor(ak.flatten(jets.jetId, axis=1).to_numpy().T, dtype=torch.float32)\n",
    "\n",
    "labels = np.array(events['LabelBranch'].array())\n",
    "y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Create masks for splitting data\n",
    "num_nodes = x.size(0)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "# Define the split (e.g., 60% training, 20% validation, 20% test)\n",
    "train_mask[:int(0.6 * num_nodes)] = True\n",
    "val_mask[int(0.6 * num_nodes):int(0.8 * num_nodes)] = True\n",
    "test_mask[int(0.8 * num_nodes):] = True\n",
    "\n",
    "# Create the data object\n",
    "from torch_geometric.data import Data\n",
    "data = Data(x=x, y=y, train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
